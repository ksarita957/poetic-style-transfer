{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Code.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksarita957/poetic-style-transfer/blob/main/Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL-GPj4518mQ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBpUZHdWJjkQ"
      },
      "source": [
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "import re\n",
        "import json\n",
        "import operator\n",
        "#Get poems from a specific author with line breaks\n",
        "def get_author_poems_lb(author):\n",
        "    ap = []\n",
        "    url = \"https://www.poetryfoundation.org/poets/\" + author\n",
        "    user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
        "    headers={'User-Agent':user_agent,}\n",
        "    exclude = set(string.punctuation)\n",
        "    request=urllib.request.Request(url,None,headers) #The assembled request\n",
        "    d = 0\n",
        "    try:\n",
        "        response = urllib.request.urlopen(request)\n",
        "    except:\n",
        "        d = None\n",
        "    if d == 0:\n",
        "        data = response.read()\n",
        "        soup = BeautifulSoup(data,features='html.parser')\n",
        "        f = soup.find(\"div\", {\"class\":\"o-tabPanel-panel\"})\n",
        "        all_poems = []\n",
        "        if f:\n",
        "            for link in f.findAll('a', attrs={'href': re.compile(\"^https://\")}):\n",
        "                all_poems.append(link.get('href'))\n",
        "            for a in all_poems:\n",
        "                request=urllib.request.Request(a,None,headers)\n",
        "                d = 0\n",
        "                try:\n",
        "                    response = urllib.request.urlopen(request)\n",
        "                except:\n",
        "                    d = None\n",
        "                if d == 0:\n",
        "                    data = response.read()\n",
        "                    sp = BeautifulSoup(data,features='html.parser')\n",
        "                    nf = sp.find(\"div\",{\"class\", \"o-poem\"})\n",
        "                    if nf is not None:\n",
        "                        plist = []\n",
        "                        s = nf.find_all(\"div\")\n",
        "                        if s:\n",
        "                            for rkl in s:\n",
        "                                j = rkl.get_text()\n",
        "                                j = ''.join(ch for ch in j if ch not in exclude)\n",
        "                                plist.append(j.strip().lower().split())\n",
        "                            if len(plist) > 0:\n",
        "                                ap.append(plist)\n",
        "    return ap\n",
        "#Get poems from specific author no line breaks\n",
        "def get_author_poems(author):\n",
        "    plist = []\n",
        "    url = \"https://www.poetryfoundation.org/poets/\" + author\n",
        "    user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
        "    headers={'User-Agent':user_agent,}\n",
        "    exclude = set(string.punctuation)\n",
        "    request=urllib.request.Request(url,None,headers) #The assembled request\n",
        "    response = urllib.request.urlopen(request)\n",
        "    data = response.read()\n",
        "    soup = BeautifulSoup(data,features='html.parser')\n",
        "    f = soup.find(\"div\", {\"class\":\"o-tabPanel-panel\"})\n",
        "    all_poems = []\n",
        "    if f:\n",
        "        for link in f.findAll('a', attrs={'href': re.compile(\"^https://\")}):\n",
        "            all_poems.append(link.get('href'))\n",
        "        for a in all_poems:\n",
        "            request=urllib.request.Request(a,None,headers)\n",
        "            response = urllib.request.urlopen(request)\n",
        "            data = response.read()\n",
        "            sp = BeautifulSoup(data,features='html.parser')\n",
        "            nf = sp.find(\"div\",{\"class\", \"o-poem\"})\n",
        "            if nf is not None:\n",
        "                s = nf.get_text(separator=' ')\n",
        "                s = ''.join(ch for ch in s if ch not in exclude)\n",
        "                plist.append(s.lower().split())\n",
        "    return plist\n",
        "#Get poems from a url\n",
        "def get_poem(poem_url):\n",
        "    user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
        "    headers={'User-Agent':user_agent,}\n",
        "    plist = []\n",
        "    request=urllib.request.Request(poem_url,None,headers)\n",
        "    response = urllib.request.urlopen(request)\n",
        "    data = response.read()\n",
        "    sp = BeautifulSoup(data,features='html.parser')\n",
        "    nf = sp.find(\"div\",{\"class\", \"o-poem\"})\n",
        "    exclude = set(string.punctuation)\n",
        "    if nf is not None:\n",
        "        s = nf.get_text(separator=' ')\n",
        "        s = ''.join(ch for ch in s if ch not in exclude)\n",
        "        plist = s.lower().split()\n",
        "    return plist\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1FbWxeNtdqS"
      },
      "source": [
        "#Get poems from four authors. Store as list of lists, where each poem is a list of lines which are in turn represented by lists\n",
        "auts = ['william-shakespeare', 'alfred-tennyson', 'rae-armantrout', 'william-wordsworth']\n",
        "author_poems = []\n",
        "author_labels = []\n",
        "i = 0\n",
        "while i < len(auts):\n",
        "  a = get_author_poems_lb(auts[i])\n",
        "  for j in a:\n",
        "    author_poems.append(j)\n",
        "    author_labels.append(i)\n",
        "  i += 1\n",
        "r_authors_poem_line = []\n",
        "i = 0\n",
        "for p in author_poems:\n",
        "  pp = []\n",
        "  for j in p:\n",
        "    jp = []\n",
        "    for word in j:\n",
        "      if '—' not in word:\n",
        "        jp.append(word)\n",
        "      else:\n",
        "        for w in word.split('—'):\n",
        "          jp.append(w)\n",
        "    pp.append(jp)\n",
        "  i += 1\n",
        "  r_authors_poem_line.append(pp)\n",
        "print(r_authors_poem_line[0])\n",
        "print(len(r_authors_poem_line))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R4-5L1gAAeH"
      },
      "source": [
        "#Creates dictionary of Vocabulary. Each word or token corresponds to a number\n",
        "from collections import Counter\n",
        "def create_vocab_dict(poems,mincount=10):\n",
        "  word_to_idx = {'<pad>':0, '<eos>':1, '<go>':2, '<unk>':3}\n",
        "  cts = {}\n",
        "  words = []\n",
        "  for p in poems:\n",
        "    for w in p:\n",
        "      for j in w:\n",
        "        words.append(j)\n",
        "  cnt= Counter(words)\n",
        "  for word in cnt:\n",
        "    if cnt[word] >= mincount:\n",
        "      word_to_idx[word]= len(word_to_idx)\n",
        "  return word_to_idx\n",
        "\n",
        "#Convert to sentences and turn words into vocab indices\n",
        "def vnorm(poems,vocab, lab, maxlen=100):\n",
        "  numpoem = []\n",
        "  indpoem = []\n",
        "  lengs = []\n",
        "  pr = 0\n",
        "  for p in poems:\n",
        "    index = lab[pr]\n",
        "    for line in p:\n",
        "      a = []\n",
        "      if len(line) > 0:\n",
        "        a.append(vocab['<go>'])\n",
        "        for h in line:\n",
        "          if h in vocab:\n",
        "            a.append(vocab[h])\n",
        "          else:\n",
        "            a.append(vocab['<unk>'])\n",
        "        if len(a) > maxlen-1:\n",
        "          a = a[0:maxlen-1]\n",
        "          a.append(vocab['<eos>'])\n",
        "          lengs.append(maxlen)\n",
        "        else:\n",
        "          a.append(vocab['<eos>'])\n",
        "          car = len(a)\n",
        "          lengs.append(car)\n",
        "          i = 0\n",
        "          while i < maxlen-car:\n",
        "            a.append(vocab['<pad>'])\n",
        "            i += 1\n",
        "        numpoem.append(a)\n",
        "        indpoem.append(index)\n",
        "    pr += 1\n",
        "  return numpoem,indpoem,lengs\n",
        "#Turns sequence of labels into a one hot matrix\n",
        "def one_hot(labs,dim):\n",
        "  oh = torch.zeros((len(labs),dim))\n",
        "  i = 0\n",
        "  while i < len(labs):\n",
        "    oh[i][labs[i]] = 1\n",
        "    i += 1\n",
        "  return oh\n",
        "cr = create_vocab_dict(r_authors_poem_line)\n",
        "padded,inds,lengs = vnorm(r_authors_poem_line,cr,author_labels)\n",
        "print(len(padded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGklHP1xogSx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np \n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "#VAE with LSTM, style as linear layer \n",
        "class LSTM_VAE(nn.Module):\n",
        "  def __init__(self, input_length, num_classes, hidden_length,layers,vocab_length, gen_length, out_length,drop=0.1,temp=10):\n",
        "    super(LSTM_VAE,self).__init__()\n",
        "    #expanding one hot of style label\n",
        "    self.style_layer = nn.Linear(num_classes,out_length)\n",
        "    #length of generation: 1 - line length\n",
        "    self.genlen = gen_length\n",
        "    #embedding dimension\n",
        "    self.inp = input_length\n",
        "    #latent dimension\n",
        "    self.out = out_length\n",
        "    #length of vocab\n",
        "    self.nvocab = vocab_length\n",
        "    #dropout later\n",
        "    self.drop = nn.Dropout(p=drop)\n",
        "    #number of layers RNN\n",
        "    self.numlayers = layers\n",
        "    #transforming encoder hidden state to mean\n",
        "    self.mean_layer = nn.Linear(layers*hidden_length,out_length)\n",
        "    #transforming decoder hidden state to log variance\n",
        "    self.var_layer = nn.Linear(layers*hidden_length,out_length)\n",
        "    #encoder LSTM\n",
        "    self.enc = nn.LSTM(input_length+out_length,hidden_length,layers,batch_first=True)\n",
        "    #Decoder LSTM\n",
        "    self.dec = nn.LSTM(input_length+2*out_length,input_length,batch_first=True)\n",
        "    #word embeddings\n",
        "    self.embedding = nn.Embedding(vocab_length,input_length, padding_idx=0)\n",
        "    #transform decoder hidden state to vector of length of vocab\n",
        "    self.llayer = nn.Linear(input_length,vocab_length)\n",
        "    #temperature\n",
        "    self.temp = temp\n",
        "  def forward(self,x,y,les):\n",
        "    #apply embedding to each word\n",
        "    x = self.embedding(x)\n",
        "    #expand style to encode style information\n",
        "    y = self.style_layer(y)\n",
        "    #concatenate style and poem information\n",
        "    ex = torch.cat((y.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "    #pack sequence to ignore pad\n",
        "    ex = pack_padded_sequence(ex,les,batch_first=True,enforce_sorted=False)\n",
        "    #get final hidden state from encoder and reshape to two dimensions\n",
        "    _,(henc,_) = self.enc(ex)\n",
        "    henc = henc.view((henc.size()[1],henc.size()[2]*self.numlayers))\n",
        "    #get mean and log variance\n",
        "    var = self.var_layer(henc)\n",
        "    mean = self.mean_layer(henc)\n",
        "    #draw new sample based on reparam trick: z = N(0,I)*var + mean\n",
        "    draw = torch.normal(torch.zeros(var.size()),torch.ones(var.size())).to(device)\n",
        "    z = draw*torch.exp(var) + mean\n",
        "    #caluclate KL-divergence\n",
        "    kl = 0.5*(torch.mean(-torch.sum(var,axis=1) + torch.sum(torch.exp(var),axis=1) + torch.sum(torch.square(mean),axis=1)-var.size()[1]))\n",
        "    #get decoder input: ground truth, latent variable, and style concatenated\n",
        "    inp = torch.zeros((x.size()[0],self.genlen,self.inp + 2*self.out)).to(device)\n",
        "    i = 0\n",
        "    while i < self.genlen:\n",
        "      inp[:,i,:] = torch.cat((z,y,x[:,i,:]),1)\n",
        "      i += 1\n",
        "    #dropout in decoder\n",
        "    inp = self.drop(inp)\n",
        "    #pack sequence to ignore padding\n",
        "    inp = pack_padded_sequence(inp,les-1,batch_first=True, enforce_sorted=False)\n",
        "    #pass through decoder\n",
        "    gen,_ = self.dec(inp)\n",
        "    #unpack and apply linear layer, then reshape to match desired shape for CrossEntropyLoss\n",
        "    gen = pad_packed_sequence(gen,batch_first=True,total_length=self.genlen)[0]\n",
        "    gen = self.llayer(gen)\n",
        "    gen = gen.view((gen.size()[0],gen.size()[2],gen.size()[1]))\n",
        "    #rescale by temperature\n",
        "    gen = (gen - torch.max(gen,1)[0].unsqueeze(1).repeat(1,len(vocab),1))/self.temp\n",
        "    return gen,kl\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbR6XjaLk5Vp"
      },
      "source": [
        "#VAE with LSTM, style as linear layer training\n",
        "#Set seeds for reproducability\n",
        "torch.backends.cudnn.deterministic = True\n",
        "np.random.seed(100)\n",
        "torch.manual_seed(100)\n",
        "torch.cuda.manual_seed(100)\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "ind = np.array(author_labels)\n",
        "#Choose which labels we want to use - only two at a time\n",
        "a0 = np.where(ind==0)[0]\n",
        "a1 = np.where(ind==1)[0]\n",
        "ind[a0] = 0\n",
        "ind[a1] = 1\n",
        "avail_poems = np.array(r_authors_poem_line,dtype='object')[np.concatenate((a0,a1))]\n",
        "avail_ind = ind[np.concatenate((a0,a1))]\n",
        "#Sequence length\n",
        "mlen = 15\n",
        "#Get vocab, labels, lengths, and numbered input for network\n",
        "vocab = create_vocab_dict(avail_poems,mincount=0)\n",
        "padded,lab,lengs = vnorm(avail_poems,vocab,avail_ind,mlen)\n",
        "#Divide data into training and validation sets\n",
        "fp = np.array(lab)\n",
        "_,rc = np.unique(fp,return_counts=True)\n",
        "cut = np.array(np.round(rc*0.8),dtype=int)\n",
        "w0 = np.where(fp==0)[0]\n",
        "w1 = np.where(fp==1)[0]\n",
        "np.random.shuffle(w0)\n",
        "np.random.shuffle(w1)\n",
        "trind =  np.concatenate((w0[0:cut[0]],w1[0:cut[1]]))\n",
        "vind = np.concatenate((w0[cut[0]:len(w0)],w1[cut[1]:len(w1)]))\n",
        "train_track = np.arange(len(trind))\n",
        "valid_track = np.arange(len(vind))\n",
        "lof = np.array(lengs)\n",
        "lengs = lof[trind]\n",
        "vlengs = lof[vind]\n",
        "input = torch.tensor(padded)[trind].to(device)\n",
        "validation = torch.tensor(padded)[vind].to(device)\n",
        "labels = torch.tensor(lab)[trind].to(device)\n",
        "vlabels = torch.tensor(lab)[vind].to(device)\n",
        "#Weighting to ignore gradient over padding and unk tokens\n",
        "weights = torch.ones(len(vocab.keys())).to(device)\n",
        "weights[0] = 0\n",
        "weights[3] = 0\n",
        "#Initialize network, loss, and optimizer\n",
        "net = LSTM_VAE(300,2,300,1,len(vocab.keys()),mlen-1,25,drop=0.1,temp=10)\n",
        "loss_func = nn.CrossEntropyLoss(weight=weights,reduction='none')\n",
        "net = net.to(device)\n",
        "optimizer = torch.optim.Adam(net.parameters(),lr=0.0001)\n",
        "batch_size = 256\n",
        "trainloss = []\n",
        "trainkl = []\n",
        "validloss = []\n",
        "validkl = []\n",
        "#coefficients for KL annealing\n",
        "klcoef = np.concatenate((np.zeros(250),np.linspace(0,1,250),np.ones(9500)))\n",
        "i = 0\n",
        "while i < 4792:\n",
        "  #Reshuffle indices each epoch\n",
        "  np.random.shuffle(train_track)\n",
        "  k = 0\n",
        "  lp = 0\n",
        "  klp = 0\n",
        "  while k < len(trind)//batch_size + 1:\n",
        "    #zero optimizer\n",
        "    optimizer.zero_grad()\n",
        "    #sample minibatch\n",
        "    inp = input[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    les = lengs[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    class_inp = one_hot(labels[train_track[k*batch_size:(k+1)*batch_size]],2).to(device)\n",
        "    #create labels for reconstruction loss\n",
        "    oh = inp.long().to(device)\n",
        "    #pass through network\n",
        "    gen,kl = net(inp,class_inp,les)\n",
        "    #record average over nonzero entries in each line and KL divergence\n",
        "    rec_loss = loss_func(gen,oh[:,1:mlen])\n",
        "    mask = rec_loss != 0\n",
        "    lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "    klp += kl.item()\n",
        "    #calculate total loss and complete backward pass\n",
        "    loss = torch.mean(loss_func(gen,oh[:,1:mlen])) + kl*klcoef[i]\n",
        "    loss.backward()\n",
        "    #gradient clip\n",
        "    torch.nn.utils.clip_grad_norm_(net.parameters(),max_norm=1)\n",
        "    optimizer.step()\n",
        "    k += 1\n",
        "  #Report avg reconstruction and KL divergence loss\n",
        "  trainloss.append(lp/len(input))\n",
        "  trainkl.append(klp/len(input))\n",
        "  #Compute same measures over validation set\n",
        "  with torch.no_grad():\n",
        "    k = 0\n",
        "    while k < len(vind)//batch_size + 1:\n",
        "      inp = validation[valid_track[k*batch_size:(k+1)*batch_size]]\n",
        "      les = vlengs[valid_track[k*batch_size:(k+1)*batch_size]]\n",
        "      oh = inp.long().to(device)\n",
        "      class_inp = one_hot(vlabels[valid_track[k*batch_size:(k+1)*batch_size]],2).to(device)\n",
        "      gen,kl = net(inp,class_inp,les)\n",
        "      rec_loss = loss_func(gen,oh[:,1:mlen])\n",
        "      mask = rec_loss != 0\n",
        "      lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "      klp += kl.item()\n",
        "      k += 1\n",
        "    validloss.append(lp/len(validation))\n",
        "    validkl.append(klp/len(validation))\n",
        "  print(i,trainloss[-1],trainkl[-1],validloss[-1],validkl[-1])\n",
        "  i += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkaYwmPlzrGu"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np \n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "#VAE with Bidirectional LSTM, style as linear layer \n",
        "class LSTM_VAE_BD(nn.Module):\n",
        "  def __init__(self, input_length, num_classes, hidden_length,layers,vocab_length, gen_length, out_length,drop=0.1,temp=10):\n",
        "    super(LSTM_VAE_BD,self).__init__()\n",
        "    #expanding one hot of style \n",
        "    self.style_layer = nn.Linear(num_classes,out_length)\n",
        "    #length of generation\n",
        "    self.genlen = gen_length\n",
        "    #dimension of embedding\n",
        "    self.inp = input_length\n",
        "    #latent dimension\n",
        "    self.out = out_length\n",
        "    #length of Vocabulary\n",
        "    self.nvocab = vocab_length\n",
        "    #dropout layer\n",
        "    self.drop = nn.Dropout(p=drop)\n",
        "    #transforming hidden state to mean of latent\n",
        "    self.mean_layer = nn.Linear(2*hidden_length,out_length)\n",
        "    #transforming hidden state to logvariance of latent\n",
        "    self.var_layer = nn.Linear(2*hidden_length,out_length)\n",
        "    #encoder \n",
        "    self.enc = nn.LSTM(input_length+out_length,hidden_length,layers,batch_first=True,bidirectional=True)\n",
        "    #decoder\n",
        "    self.dec = nn.LSTM(input_length+2*out_length,input_length,batch_first=True)\n",
        "    #word embeddings\n",
        "    self.embedding = nn.Embedding(vocab_length,input_length, padding_idx=0)\n",
        "    #transform decoder hidden state to vector of length of vocab\n",
        "    self.llayer = nn.Linear(input_length,vocab_length)\n",
        "    #number of layers\n",
        "    self.numlayers = layers\n",
        "    #temperature\n",
        "    self.temp = temp\n",
        "  def forward(self,x,y,les):\n",
        "    #apply embedding to input\n",
        "    x = self.embedding(x)\n",
        "    #expand style information\n",
        "    y = self.style_layer(y)\n",
        "    #pack sequence to ignore padding\n",
        "    ex = torch.cat((y.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "    ex = pack_padded_sequence(ex,les,batch_first=True,enforce_sorted=False)\n",
        "    #pass through encoder\n",
        "    _,(henc,_) = self.enc(ex)\n",
        "    henc = henc.view((henc.size()[1],henc.size()[2]*2*self.numlayers))\n",
        "    #get mean and log variance of latent dimension\n",
        "    var = self.var_layer(henc)\n",
        "    mean = self.mean_layer(henc)\n",
        "    #draw new sample based on reparam trick: z = N(0,I)*var + mean\n",
        "    draw = torch.normal(torch.zeros(var.size()),torch.ones(var.size())).to(device)\n",
        "    z = draw*torch.exp(var) + mean\n",
        "    #calculate kl divergence\n",
        "    kl = 0.5*(torch.mean(-torch.sum(var,axis=1) + torch.sum(torch.exp(var),axis=1) + torch.sum(torch.square(mean),axis=1)-var.size()[1]))\n",
        "    #create input for decoder with teacher forcing - concatenate latent,stlye, and input\n",
        "    inp = torch.zeros((x.size()[0],self.genlen,self.inp + 2*self.out)).to(device)\n",
        "    i = 0\n",
        "    while i < self.genlen:\n",
        "      inp[:,i,:] = torch.cat((z,y,x[:,i,:]),1)\n",
        "      i += 1\n",
        "    #dropout layer\n",
        "    inp = self.drop(inp)\n",
        "    #pack sequence for decoder\n",
        "    inp = pack_padded_sequence(inp,les-1,batch_first=True, enforce_sorted=False)\n",
        "    #pass through decoder and unpack\n",
        "    gen,_ = self.dec(inp)\n",
        "    gen = pad_packed_sequence(gen,batch_first=True,total_length=self.genlen)[0]\n",
        "    #expand to vector over vocab and reshape for CrossEntropyLoss\n",
        "    gen = self.llayer(gen)\n",
        "    gen = gen.view((gen.size()[0],gen.size()[2],gen.size()[1]))\n",
        "    #rescale by temperature\n",
        "    gen = (gen - torch.max(gen,1)[0].unsqueeze(1).repeat(1,len(vocab),1))/self.temp\n",
        "    return gen,kl\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fLviPaT6r_k"
      },
      "source": [
        "#VAE with LSTM, style as linear layer training\n",
        "#Set seeds for reproducability\n",
        "torch.backends.cudnn.deterministic = True\n",
        "np.random.seed(100)\n",
        "torch.manual_seed(100)\n",
        "torch.cuda.manual_seed(100)\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "ind = np.array(author_labels)\n",
        "#Choose which labels we want to use - only two at a time\n",
        "a0 = np.where(ind==0)[0]\n",
        "a1 = np.where(ind==1)[0]\n",
        "ind[a0] = 0\n",
        "ind[a1] = 1\n",
        "avail_poems = np.array(r_authors_poem_line,dtype='object')[np.concatenate((a0,a1))]\n",
        "avail_ind = ind[np.concatenate((a0,a1))]\n",
        "#Sequence length\n",
        "mlen = 15\n",
        "#Get vocab, labels, lengths, and numbered input for network\n",
        "vocab = create_vocab_dict(avail_poems,mincount=0)\n",
        "padded,lab,lengs = vnorm(avail_poems,vocab,avail_ind,mlen)\n",
        "#Divide data into training and validation sets\n",
        "fp = np.array(lab)\n",
        "_,rc = np.unique(fp,return_counts=True)\n",
        "cut = np.array(np.round(rc*0.8),dtype=int)\n",
        "w0 = np.where(fp==0)[0]\n",
        "w1 = np.where(fp==1)[0]\n",
        "np.random.shuffle(w0)\n",
        "np.random.shuffle(w1)\n",
        "trind =  np.concatenate((w0[0:cut[0]],w1[0:cut[1]]))\n",
        "vind = np.concatenate((w0[cut[0]:len(w0)],w1[cut[1]:len(w1)]))\n",
        "train_track = np.arange(len(trind))\n",
        "valid_track = np.arange(len(vind))\n",
        "lof = np.array(lengs)\n",
        "lengs = lof[trind]\n",
        "vlengs = lof[vind]\n",
        "input = torch.tensor(padded)[trind].to(device)\n",
        "validation = torch.tensor(padded)[vind].to(device)\n",
        "labels = torch.tensor(lab)[trind].to(device)\n",
        "vlabels = torch.tensor(lab)[vind].to(device)\n",
        "#Weighting to ignore gradient over padding and unk tokens\n",
        "weights = torch.ones(len(vocab.keys())).to(device)\n",
        "weights[0] = 0\n",
        "weights[3] = 0\n",
        "#initialize network,loss, and optimizer\n",
        "net = LSTM_VAE_BD(300,2,300,1,len(vocab.keys()),mlen-1,25,drop=0.1,temp=10)\n",
        "loss_func = nn.CrossEntropyLoss(weight=weights,reduction='none')\n",
        "net = net.to(device)\n",
        "optimizer = torch.optim.Adam(net.parameters(),lr=0.0001)\n",
        "batch_size = 256\n",
        "trainloss = []\n",
        "trainkl = []\n",
        "validloss = []\n",
        "validkl = []\n",
        "#coefficients for annealing\n",
        "klcoef = np.concatenate((np.zeros(250),np.linspace(0,1,250),np.ones(9500)))\n",
        "i = 0\n",
        "while i < 10000:\n",
        "  #randomize minibatch\n",
        "  np.random.shuffle(train_track)\n",
        "  k = 0\n",
        "  lp = 0\n",
        "  klp = 0\n",
        "  while k < len(trind)//batch_size + 1:\n",
        "    #zero out optimizer\n",
        "    optimizer.zero_grad()\n",
        "    #get input, labels, lengths for packing\n",
        "    inp = input[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    les = lengs[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    class_inp = one_hot(labels[train_track[k*batch_size:(k+1)*batch_size]],2).to(device)\n",
        "    #labels for rec error\n",
        "    oh = inp.long().to(device)\n",
        "    #pass through network\n",
        "    gen,kl = net(inp,class_inp,les)\n",
        "    #record average loss over nonzero losses\n",
        "    rec_loss = loss_func(gen,oh[:,1:mlen])\n",
        "    mask = rec_loss != 0\n",
        "    lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "    klp += kl.item()\n",
        "    #backpropagation\n",
        "    loss = torch.mean(loss_func(gen,oh[:,1:mlen])) + kl*klcoef[i]\n",
        "    loss.backward()\n",
        "    #gradient clip\n",
        "    torch.nn.utils.clip_grad_norm_(net.parameters(),max_norm=1)\n",
        "    optimizer.step()\n",
        "    k += 1\n",
        "  trainloss.append(lp/len(input))\n",
        "  trainkl.append(klp/len(input))\n",
        "  #Calculate loss over validation set\n",
        "  with torch.no_grad():\n",
        "    k = 0\n",
        "    while k < len(vind)//batch_size + 1:\n",
        "      inp = validation[valid_track[k*batch_size:(k+1)*batch_size]]\n",
        "      les = vlengs[valid_track[k*batch_size:(k+1)*batch_size]]\n",
        "      oh = inp.long().to(device)\n",
        "      class_inp = one_hot(vlabels[valid_track[k*batch_size:(k+1)*batch_size]],2).to(device)\n",
        "      gen,kl = net(inp,class_inp,les)\n",
        "      rec_loss = loss_func(gen,oh[:,1:mlen])\n",
        "      mask = rec_loss != 0\n",
        "      lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "      klp += kl.item()\n",
        "      k += 1\n",
        "    validloss.append(lp/len(validation))\n",
        "    validkl.append(klp/len(validation))\n",
        "  print(i,trainloss[-1],trainkl[-1],validloss[-1],validkl[-1])\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwQkm-Az8xbm"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np \n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch.nn.functional import softmax\n",
        "device = torch.device('cuda:0')\n",
        "#VAE with LSTM and Attention,style as Linear Layer\n",
        "class LSTM_ATN_VAE(nn.Module):\n",
        "  def __init__(self, input_length, hidden_z,num_classes, out_length, attn_length, layers,vocab_length, gen_length,drop=0.1,temp=10):\n",
        "    super(LSTM_ATN_VAE,self).__init__()\n",
        "    #length of generation\n",
        "    self.genlen = gen_length\n",
        "    #embedding dim\n",
        "    self.inp = input_length\n",
        "    #vocab length\n",
        "    self.nvocab = vocab_length\n",
        "    #length of latent dim\n",
        "    self.out = out_length\n",
        "    #hidden length of encoder - nedded for attention\n",
        "    self.hidz = hidden_z\n",
        "    #number of layers\n",
        "    self.layers = layers\n",
        "    #mean and variance layer\n",
        "    self.mean_layer = nn.Linear(layers*hidden_z,out_length)\n",
        "    self.var_layer = nn.Linear(layers*hidden_z,out_length)\n",
        "    #encoder\n",
        "    self.enc_z = nn.LSTM(input_length+out_length,hidden_z,layers,batch_first=True)\n",
        "    #style information linear layer\n",
        "    self.style_expand = nn.Linear(num_classes,out_length)\n",
        "    #generator cell - iterated over sequence length - 1 for decoded sequence\n",
        "    self.dec = nn.LSTMCell(input_length+hidden_z+out_length,out_length)\n",
        "    #attention linear layer over encoder hidden\n",
        "    self.attn_enc = nn.Linear(hidden_z,attn_length)\n",
        "    #attention linear layer over current generator hidden\n",
        "    self.attn_hid = nn.Linear(out_length,attn_length)\n",
        "    #reduce to vector\n",
        "    self.attn_reduce = nn.Linear(attn_length,1)\n",
        "    #ReLU activation\n",
        "    self.relu = nn.ReLU()\n",
        "    #word embeddings\n",
        "    self.embedding = nn.Embedding(vocab_length,input_length, padding_idx=0)\n",
        "    #dropout\n",
        "    self.drop = nn.Dropout(p=drop)\n",
        "    #expand to vocab size\n",
        "    self.llayer = nn.Linear(out_length,vocab_length)\n",
        "    #number of layers\n",
        "    self.numlayers = layers\n",
        "    #softmax\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    #temperature\n",
        "    self.temp = temp\n",
        "  def forward(self,x,y,les):\n",
        "    #matrix of word embeddings\n",
        "    x = self.embedding(x)\n",
        "    #getting style information\n",
        "    y = self.style_expand(y)\n",
        "    #feeding packed sequence through encoder, switching back to padded\n",
        "    ex = torch.cat((y.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "    ex = pack_padded_sequence(ex,les,batch_first=True,enforce_sorted=False)\n",
        "    out,(hz,_) = self.enc_z(ex)\n",
        "    out = pad_packed_sequence(out,batch_first=True,total_length=x.size()[1])[0]\n",
        "    #converts hidden layer to latent mean/logvariance\n",
        "    hz = hz.view((hz.size()[1],hz.size()[2]*(self.numlayers)))\n",
        "    mean = self.mean_layer(hz)\n",
        "    var= self.var_layer(hz)\n",
        "    #draw from distribution\n",
        "    draw = torch.normal(torch.zeros(var.size()),torch.ones(var.size())).to(device)\n",
        "    z = draw*torch.exp(var) + mean\n",
        "    #calculate KL divergence\n",
        "    kl = 0.5*(torch.mean(-torch.sum(var,axis=1) + torch.sum(torch.exp(var),axis=1) + torch.sum(torch.square(mean),axis=1)-var.size()[1]))\n",
        "    #iterating over generation length\n",
        "    gen = torch.zeros((x.size()[0],self.nvocab,self.genlen)).to(device)\n",
        "    i = 0\n",
        "    while i < self.genlen:\n",
        "      #calculate attention weights\n",
        "      attn_weights = self.softmax(self.attn_reduce(self.relu(self.attn_enc(out) + self.attn_hid(z.unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "      attn_weights = attn_weights.view((attn_weights.size()[0],1,attn_weights.size()[1]))\n",
        "      #apply weights to encoder hidden state\n",
        "      attn_vec = torch.bmm(attn_weights,out)\n",
        "      attn_vec = attn_vec.view((attn_vec.size()[0],attn_vec.size()[2]))\n",
        "      #create new input\n",
        "      inp = torch.cat((attn_vec,y,x[:,i,:]),1)\n",
        "      #dropout\n",
        "      inp = self.drop(inp)\n",
        "      #pass through generator\n",
        "      z,_ = self.dec(inp)\n",
        "      #expand to vocab length\n",
        "      g = self.llayer(z)\n",
        "      gen[:,:,i] = g\n",
        "      i += 1\n",
        "    #rescale with temperature\n",
        "    gen = (gen - torch.max(gen,1)[0].unsqueeze(1).repeat(1,len(vocab),1))/self.temp\n",
        "    return gen,kl\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGO78pTZ-XOe"
      },
      "source": [
        "#VAE with LSTM and attention, style as linear layer training\n",
        "#Set seeds for reproducability\n",
        "torch.backends.cudnn.deterministic = True\n",
        "np.random.seed(100)\n",
        "torch.manual_seed(100)\n",
        "torch.cuda.manual_seed(100)\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "ind = np.array(author_labels)\n",
        "#Choose which labels we want to use - only two at a time\n",
        "a0 = np.where(ind==0)[0]\n",
        "a1 = np.where(ind==2)[0]\n",
        "ind[a0] = 0\n",
        "ind[a1] = 1\n",
        "avail_poems = np.array(r_authors_poem_line,dtype='object')[np.concatenate((a0,a1))]\n",
        "avail_ind = ind[np.concatenate((a0,a1))]\n",
        "#Sequence length\n",
        "mlen = 15\n",
        "#Get vocab, labels, lengths, and numbered input for network\n",
        "vocab = create_vocab_dict(avail_poems,mincount=0)\n",
        "padded,lab,lengs = vnorm(avail_poems,vocab,avail_ind,mlen)\n",
        "#Divide data into training and validation sets\n",
        "fp = np.array(lab)\n",
        "_,rc = np.unique(fp,return_counts=True)\n",
        "cut = np.array(np.round(rc*0.8),dtype=int)\n",
        "w0 = np.where(fp==0)[0]\n",
        "w1 = np.where(fp==1)[0]\n",
        "np.random.shuffle(w0)\n",
        "np.random.shuffle(w1)\n",
        "trind =  np.concatenate((w0[0:cut[0]],w1[0:cut[1]]))\n",
        "vind = np.concatenate((w0[cut[0]:len(w0)],w1[cut[1]:len(w1)]))\n",
        "train_track = np.arange(len(trind))\n",
        "valid_track = np.arange(len(vind))\n",
        "lof = np.array(lengs)\n",
        "lengs = lof[trind]\n",
        "vlengs = lof[vind]\n",
        "input = torch.tensor(padded)[trind].to(device)\n",
        "validation = torch.tensor(padded)[vind].to(device)\n",
        "labels = torch.tensor(lab)[trind].to(device)\n",
        "vlabels = torch.tensor(lab)[vind].to(device)\n",
        "#weighting to ignore gradient over padding and unk tokens\n",
        "weights = torch.ones(len(vocab.keys())).to(device)\n",
        "weights[0] = 0\n",
        "weights[3] = 0\n",
        "#initialize network,loss, and optimizer\n",
        "net = LSTM_ATN_VAE(300,100,2,300,100,1,len(vocab.keys()),mlen-1,0.1,temp=10)\n",
        "loss_func = nn.CrossEntropyLoss(weight=weights,reduction='none')\n",
        "net = net.to(device)\n",
        "optimizer = torch.optim.Adam(net.parameters(),lr=0.0001)\n",
        "batch_size = 256\n",
        "trainloss = []\n",
        "trainkl = []\n",
        "validloss = []\n",
        "validkl = []\n",
        "#coefficient for KL annealing\n",
        "klcoef = np.concatenate((np.zeros(250),np.linspace(0,1,250),np.ones(9500)))\n",
        "i = 0\n",
        "while i < 5280:\n",
        "  #sample random minibatch\n",
        "  np.random.shuffle(train_track)\n",
        "  k = 0\n",
        "  lp = 0\n",
        "  klp = 0\n",
        "  while k < len(trind)//batch_size + 1:\n",
        "    #zero gradient\n",
        "    optimizer.zero_grad()\n",
        "    #get input, lengths, and class input for minibatch\n",
        "    inp = input[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    les = lengs[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    oh = inp.long().to(device)\n",
        "    class_inp = one_hot(labels[train_track[k*batch_size:(k+1)*batch_size]],2).to(device)\n",
        "    #pass through network\n",
        "    gen,kl = net(inp,class_inp,les)\n",
        "    #record loss\n",
        "    rec_loss = loss_func(gen,oh[:,1:mlen])\n",
        "    mask = rec_loss != 0\n",
        "    lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "    klp += kl.item()\n",
        "    #backward gradient\n",
        "    loss = torch.mean(loss_func(gen,oh[:,1:mlen])) + kl*klcoef[i]\n",
        "    loss.backward()\n",
        "    #clip gradient\n",
        "    torch.nn.utils.clip_grad_norm_(net.parameters(),max_norm=1)\n",
        "    optimizer.step()\n",
        "    k += 1\n",
        "  trainloss.append(lp/len(input))\n",
        "  trainkl.append(klp/len(input))\n",
        "  #find loss over validation set\n",
        "  with torch.no_grad():\n",
        "    k = 0\n",
        "    while k < len(vind)//batch_size + 1:\n",
        "      inp = validation[valid_track[k*batch_size:(k+1)*batch_size]]\n",
        "      les = vlengs[valid_track[k*batch_size:(k+1)*batch_size]]\n",
        "      oh = inp.long().to(device)\n",
        "      class_inp = one_hot(vlabels[valid_track[k*batch_size:(k+1)*batch_size]],2).to(device)\n",
        "      gen,kl = net(inp,class_inp,les)\n",
        "      rec_loss = loss_func(gen,oh[:,1:mlen])\n",
        "      mask = rec_loss != 0\n",
        "      lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "      klp += kl.item()\n",
        "      k += 1\n",
        "    validloss.append(lp/len(validation))\n",
        "    validkl.append(klp/len(validation))\n",
        "  print(i,trainloss[-1],trainkl[-1],validloss[-1],validkl[-1])\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ7XQ7AUF5Vo"
      },
      "source": [
        "#Loading a saved ATN VAE model\n",
        "torch.backends.cudnn.deterministic = True\n",
        "np.random.seed(100)\n",
        "torch.manual_seed(100)\n",
        "torch.cuda.manual_seed(100)\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "ind = np.array(author_labels)\n",
        "#Choose which labels we want to use - only two at a time\n",
        "a0 = np.where(ind==0)[0]\n",
        "a1 = np.where(ind==1)[0]\n",
        "ind[a0] = 0\n",
        "ind[a1] = 1\n",
        "avail_poems = np.array(r_authors_poem_line,dtype='object')[np.concatenate((a0,a1))]\n",
        "avail_ind = ind[np.concatenate((a0,a1))]\n",
        "#Sequence length\n",
        "mlen = 15\n",
        "#Get vocab, labels, lengths, and numbered input for network\n",
        "vocab = create_vocab_dict(avail_poems,mincount=0)\n",
        "padded,lab,lengs = vnorm(avail_poems,vocab,avail_ind,mlen)\n",
        "fp = np.array(lab)\n",
        "_,rc = np.unique(fp,return_counts=True)\n",
        "cut = np.array(np.round(rc*0.8),dtype=int)\n",
        "w0 = np.where(fp==0)[0]\n",
        "w1 = np.where(fp==1)[0]\n",
        "np.random.shuffle(w0)\n",
        "np.random.shuffle(w1)\n",
        "trind =  np.concatenate((w0[0:cut[0]],w1[0:cut[1]]))\n",
        "vind = np.concatenate((w0[cut[0]:len(w0)],w1[cut[1]:len(w1)]))\n",
        "#Divide data into training and validation sets\n",
        "train_track = np.arange(len(trind))\n",
        "valid_track = np.arange(len(vind))\n",
        "lof = np.array(lengs)\n",
        "lengs = lof[trind]\n",
        "vlengs = lof[vind]\n",
        "input = torch.tensor(padded)[trind].to(device)\n",
        "validation = torch.tensor(padded)[vind].to(device)\n",
        "labels = torch.tensor(lab)[trind].to(device)\n",
        "vlabels = torch.tensor(lab)[vind].to(device)\n",
        "#Weighting to ignore gradient over padding and unk tokens\n",
        "weights = torch.ones(len(vocab.keys())).to(device)\n",
        "weights[3] = 0\n",
        "weights[0] = 0\n",
        "net = LSTM_ATN_VAE(300,100,2,300,100,1,len(vocab.keys()),mlen-1,drop=0.1,temp=10)\n",
        "loss_func = nn.CrossEntropyLoss(weight=weights,reduction='none')\n",
        "net = net.to(device)\n",
        "#Change path to where model is saved - make sure labels are consistent with chosen\n",
        "net.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/Thesis/ATN_VAE_0_1.pt'))\n",
        "net.eval()\n",
        "batch_size=256\n",
        "lp = 0\n",
        "with torch.no_grad():\n",
        "  k = 0\n",
        "  while k < len(vind)//batch_size + 1:\n",
        "    inp = validation[valid_track[k*batch_size:(k+1)*batch_size]]\n",
        "    les = vlengs[valid_track[k*batch_size:(k+1)*batch_size]]\n",
        "    oh = inp.long().to(device)\n",
        "    class_inp = one_hot(vlabels[valid_track[k*batch_size:(k+1)*batch_size]],2).to(device)\n",
        "    gen,kl = net(inp,class_inp,les)\n",
        "    rec_loss = loss_func(gen,oh[:,1:mlen])\n",
        "    mask = rec_loss != 0\n",
        "    lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "    k += 1\n",
        "print(lp/len(validation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e8j1pXl2e40"
      },
      "source": [
        "#Base classifier\n",
        "np.random.seed(100)\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "#term frequency matrix\n",
        "def tf(poems):\n",
        "  vocab = []\n",
        "  for p in poems:\n",
        "    for s in p:\n",
        "      for st in s: \n",
        "        if st not in vocab:\n",
        "          vocab.append(st)\n",
        "  mat_tf = np.zeros((len(poems),len(vocab)))\n",
        "  i = 0\n",
        "  while i < len(poems):\n",
        "    for line in poems[i]:\n",
        "      for word in line:\n",
        "        mat_tf[i,vocab.index(word)] += 1\n",
        "    i += 1\n",
        "  return mat_tf,vocab\n",
        "def to_mat(p,voc):\n",
        "  mat = np.zeros((len(p),len(voc)))\n",
        "  i = 0\n",
        "  for poem in p:\n",
        "    for line in poem:\n",
        "      for word in line:\n",
        "        if word in voc:\n",
        "          mat[i,voc.index(word)] += 1\n",
        "    i += 1\n",
        "  return mat\n",
        "mtf,avail_vocab = tf(avail_poems)\n",
        "plabels = np.array(avail_ind)\n",
        "#train classifier\n",
        "X_train,X_test,y_train,y_test = train_test_split(mtf,plabels,test_size=0.33,random_state=100,stratify=plabels)\n",
        "clf = LinearSVC(random_state=100)\n",
        "clf.fit(X_train,y_train)\n",
        "pred = clf.predict(X_test)\n",
        "print(len(np.where(pred==y_test)[0])/len(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_qvI0E-1hgd"
      },
      "source": [
        "#here we generate transferred poems and find style transfer intensity + classification accuracy\n",
        "#list of vocab\n",
        "ke = list(vocab.keys())\n",
        "#beam width for beam search\n",
        "beam_width = 50\n",
        "real_poems = []\n",
        "transferred_poems = []\n",
        "sample_labels = []\n",
        "print(len(avail_poems))\n",
        "#iterate over all available poems\n",
        "i = 0\n",
        "while i < len(avail_poems):\n",
        "  av = avail_poems[i]\n",
        "  real_poems.append(av)\n",
        "  sample_labels.append(avail_ind[i])\n",
        "  genpoem = []\n",
        "  for line in av:\n",
        "    if len(line) == 0:\n",
        "      pass\n",
        "    else:\n",
        "      #get acutal label and modified label\n",
        "      curlab = one_hot([avail_ind[i]],2).to(device)\n",
        "      modlab = one_hot([1 - avail_ind[i]],2).to(device)\n",
        "      #generate input as numbers\n",
        "      leng = []\n",
        "      a = []\n",
        "      a.append(vocab['<go>'])\n",
        "      for h in line:\n",
        "        if h in vocab:\n",
        "          a.append(vocab[h])\n",
        "        else:\n",
        "          a.append(vocab['<unk>'])\n",
        "      if len(a) > mlen-1:\n",
        "        a = a[0:mlen-1]\n",
        "        a.append(vocab['<eos>'])\n",
        "        leng.append(mlen)\n",
        "      else:\n",
        "        a.append(vocab['<eos>'])\n",
        "        car = len(a)\n",
        "        leng.append(car)\n",
        "        j = 0\n",
        "        while j < mlen-car:\n",
        "          a.append(vocab['<pad>'])\n",
        "          j += 1\n",
        "      with torch.no_grad():\n",
        "        #create input matrix\n",
        "        x = torch.tensor(a).to(device).reshape((1,-1))\n",
        "        les = torch.tensor(leng)\n",
        "        #get embedding\n",
        "        x = net.embedding(x)\n",
        "        #linear style information for real and transferred label\n",
        "        y = net.style_expand(curlab)\n",
        "        mody = net.style_expand(modlab)\n",
        "        #pass through encoder with real label\n",
        "        ex = torch.cat((y.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "        ex = pack_padded_sequence(ex,les,batch_first=True,enforce_sorted=False)\n",
        "        out,(hz,_) = net.enc_z(ex)\n",
        "        out = pad_packed_sequence(out,batch_first=True,total_length=x.size()[1])[0]\n",
        "        #draw from prior\n",
        "        z = torch.normal(torch.zeros((x.size()[0],net.out)),torch.ones((x.size()[0],net.out))).to(device)\n",
        "        gen = []\n",
        "        #iterate over generation length\n",
        "        k = 0\n",
        "        while k < mlen-1:\n",
        "          #at first step we only have one real input\n",
        "          if k == 0:\n",
        "            #create attention vector\n",
        "            attn_weights = net.softmax(net.attn_reduce(net.relu(net.attn_enc(out) + net.attn_hid(z.unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "            attn_weights = attn_weights.view((attn_weights.size()[0],1,attn_weights.size()[1]))\n",
        "            attn_vec = torch.bmm(attn_weights,out)\n",
        "            attn_vec = attn_vec.view((attn_vec.size()[0],attn_vec.size()[2]))\n",
        "            #create input\n",
        "            inp = torch.cat((attn_vec,mody,x[:,k,:]),1)\n",
        "            #pass through decoder\n",
        "            z,_ = net.dec(inp)\n",
        "            #expand to vocab size\n",
        "            ou = net.llayer(z)\n",
        "            #store hidden state for attention - same for each beam\n",
        "            z = z.repeat(beam_width,1)\n",
        "            #store encoder hidden states for attention - same for each beam\n",
        "            out = out.repeat(beam_width,1,1)\n",
        "            #get top n with n specified by beam width\n",
        "            ou = torch.nn.functional.softmax(ou.reshape((-1)),dim=0)\n",
        "            bind = torch.argsort(ou,descending=True)[0:beam_width]\n",
        "            #get embeddings\n",
        "            ip = net.embedding(bind)\n",
        "            #get probabilities\n",
        "            prob = ou[bind]\n",
        "            #store words\n",
        "            ct = 0\n",
        "            while ct < len(bind):\n",
        "              gen.append([ke[bind[ct].cpu().item()]])\n",
        "              ct += 1\n",
        "          else:\n",
        "            #create attention vectors\n",
        "            attn_weights = net.softmax(net.attn_reduce(net.relu(net.attn_enc(out) + net.attn_hid(z.unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "            attn_weights = attn_weights.view((attn_weights.size()[0],1,attn_weights.size()[1]))\n",
        "            attn_vec = torch.bmm(attn_weights,out)\n",
        "            attn_vec = attn_vec.view((attn_vec.size()[0],attn_vec.size()[2]))\n",
        "            #create input (batch size of beam width)\n",
        "            inp = torch.cat((attn_vec,mody.repeat(beam_width,1),ip),1)\n",
        "            #pass through decoder\n",
        "            z,_ = net.dec(inp)\n",
        "            #expand to vocab length\n",
        "            ou = net.llayer(z)\n",
        "            #get top n by beam width for each beam\n",
        "            ou = torch.nn.functional.softmax(ou,dim=1)\n",
        "            aval,aind = torch.sort(ou,dim=1,descending=True)\n",
        "            aval = aval[:,0:beam_width]\n",
        "            aind = aind[:,0:beam_width]\n",
        "            #get probabilities for each overall sequence - multiply current prob by original beam prob\n",
        "            aval = aval*(prob.unsqueeze(0).repeat(beam_width,1))\n",
        "            #get top n overall\n",
        "            aval = aval.reshape((beam_width**2))\n",
        "            bind = torch.argsort(aval,descending=True)[0:beam_width]\n",
        "            #store new probabilities\n",
        "            prob = aval[bind]\n",
        "            ip = torch.zeros((beam_width,x.size()[2])).to(device)\n",
        "            ct = 0\n",
        "            ge = []\n",
        "            #store word and embedding corresponding to the top n sequences by beam width\n",
        "            while ct < len(bind):\n",
        "              xind = bind[ct].cpu().item()//beam_width\n",
        "              yind = bind[ct].cpu().item()%beam_width\n",
        "              ip[ct] = net.embedding(aind[xind,yind])\n",
        "              ge.append(gen[xind] + [ke[aind[xind,yind].cpu().item()]])\n",
        "              ct += 1\n",
        "            gen = ge.copy()\n",
        "          k += 1\n",
        "      #append list of beam sequences for each generated line\n",
        "      genpoem.append(gen)\n",
        "  l = 0\n",
        "  rp = []\n",
        "  while l < len(genpoem):\n",
        "    #choose best generated line and convert to engliosh sentence\n",
        "    gp = genpoem[l][0]\n",
        "    rl = []\n",
        "    for word in gp:\n",
        "      if word in ['<pad>', '<unk>', '<go>']:\n",
        "        pass\n",
        "      elif word == '<eos>':\n",
        "        break\n",
        "      else:\n",
        "        rl.append(word)\n",
        "    rp.append(rl)\n",
        "    l += 1\n",
        "  #append new poem to transferred poem\n",
        "  transferred_poems.append(rp)\n",
        "  print(i)\n",
        "  i += 1\n",
        "#Calculate style transfer intensity and classification accuracy\n",
        "i = 0\n",
        "avchange = 0\n",
        "better = np.zeros(len(real_poems))\n",
        "tclass = np.zeros(len(real_poems))\n",
        "while i < len(real_poems):\n",
        "  rlab = sample_labels[i]\n",
        "  tmat = to_mat([real_poems[i]] + [transferred_poems[i]],avail_vocab)\n",
        "  df = clf.decision_function(tmat)\n",
        "  pred = clf.predict(tmat)\n",
        "  if rlab == 0:\n",
        "    avchange += (df[1] - df[0])/np.abs(df[0])\n",
        "    if pred[1] == 1:\n",
        "      tclass[i] = 1\n",
        "  else:\n",
        "    avchange += (df[0] - df[1])/np.abs(df[0])\n",
        "    if pred[1] == 0:\n",
        "      tclass[i] = 1\n",
        "  i += 1\n",
        "print('Style Transfer Intensity')\n",
        "print(avchange/i)\n",
        "print('Classification Accuracy')\n",
        "print(np.sum(tclass)/len(tclass))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt9khmVRsyWI"
      },
      "source": [
        "#Can experiment with transferring specific poems\n",
        "sp = np.array(sample_labels)\n",
        "tc = np.array(tclass)\n",
        "print(np.where(tclass==0)[0])\n",
        "print(np.where(tclass==1)[0])\n",
        "print(np.where(sp==0)[0])\n",
        "print(np.where(sp==1)[0])\n",
        "ind = 92\n",
        "print(tclass[ind])\n",
        "print('Real Poem:')\n",
        "for r in real_poems[ind]:\n",
        "  st = ''\n",
        "  for word in r:\n",
        "    st += word + ' '\n",
        "  print(st)\n",
        "print('Transferred Poem:')\n",
        "for r in transferred_poems[ind]:\n",
        "  st = ''\n",
        "  for word in r:\n",
        "    st += word + ' '\n",
        "  print(st)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbA4hDzE5Oac"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np \n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch.nn.functional import softmax\n",
        "device = torch.device('cuda:0')\n",
        "#VAE with bidirectional LSTM and Attention,style as linear layer\n",
        "class LSTM_ATN_VAE_BD(nn.Module):\n",
        "  def __init__(self, input_length, hidden_z,num_classes, out_length, attn_length, layers,vocab_length, gen_length,drop=0.1,temp=10):\n",
        "    super(LSTM_ATN_VAE_BD,self).__init__()\n",
        "    #generation length\n",
        "    self.genlen = gen_length\n",
        "    #input length\n",
        "    self.inp = input_length\n",
        "    #vocab length\n",
        "    self.nvocab = vocab_length\n",
        "    #latent dim\n",
        "    self.out = out_length\n",
        "    #hidden dim of encoder\n",
        "    self.hidz = hidden_z\n",
        "    #number of layers\n",
        "    self.numlayers = layers\n",
        "    #mean and logvariance layers\n",
        "    self.mean_layer = nn.Linear(2*layers*hidden_z,out_length)\n",
        "    self.var_layer = nn.Linear(2*layers*hidden_z,out_length)\n",
        "    #encoder\n",
        "    self.enc_z = nn.LSTM(input_length+out_length,hidden_z,layers,batch_first=True,bidirectional=True)\n",
        "    #linear layer for style\n",
        "    self.style_expand = nn.Linear(num_classes,out_length)\n",
        "    #generator\n",
        "    self.dec = nn.LSTMCell(input_length+2*hidden_z+out_length,out_length)\n",
        "    #attention linear layer for encoder hidden\n",
        "    self.attn_enc = nn.Linear(2*hidden_z,attn_length)\n",
        "    #attention linear layer for generator hidden\n",
        "    self.attn_hid = nn.Linear(out_length,attn_length)\n",
        "    #convert to vector\n",
        "    self.attn_reduce = nn.Linear(attn_length,1)\n",
        "    #dropout\n",
        "    self.drop = nn.Dropout(p=drop)\n",
        "    #ReLU activation\n",
        "    self.relu = nn.ReLU()\n",
        "    #word emebedding\n",
        "    self.embedding = nn.Embedding(vocab_length,input_length, padding_idx=0)\n",
        "    #softmax layer\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    #linear layer to expand to vocab length\n",
        "    self.llayer = nn.Linear(out_length,vocab_length)\n",
        "    #temperature\n",
        "    self.temp = temp\n",
        "  def forward(self,x,y,les):\n",
        "    #get word embeddings\n",
        "    x = self.embedding(x)\n",
        "    #expand for style information\n",
        "    y = self.style_expand(y)\n",
        "    #pass packed sequence through encoder and unpack\n",
        "    ex = torch.cat((y.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "    ex = pack_padded_sequence(ex,les,batch_first=True,enforce_sorted=False)\n",
        "    out,(hz,_) = self.enc_z(ex)\n",
        "    out = pad_packed_sequence(out,batch_first=True,total_length=x.size()[1])[0]\n",
        "    #get mean and log variance of latent\n",
        "    hz = hz.view((hz.size()[1],hz.size()[2]*2*(self.numlayers)))\n",
        "    mean = self.mean_layer(hz)\n",
        "    var= self.var_layer(hz)\n",
        "    #draw from distribution with reparametrization trick\n",
        "    draw = torch.normal(torch.zeros(var.size()),torch.ones(var.size())).to(device)\n",
        "    z = draw*torch.exp(var) + mean\n",
        "    #get KL divergence\n",
        "    kl = 0.5*(torch.mean(-torch.sum(var,axis=1) + torch.sum(torch.exp(var),axis=1) + torch.sum(torch.square(mean),axis=1)-var.size()[1]))\n",
        "    gen = torch.zeros((x.size()[0],self.nvocab,self.genlen)).to(device)\n",
        "    #iterate over gen length\n",
        "    i = 0\n",
        "    while i < self.genlen:\n",
        "      #create attention weights\n",
        "      attn_weights = self.softmax(self.attn_reduce(self.relu(self.attn_enc(out) + self.attn_hid(z.unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "      attn_weights = attn_weights.view((attn_weights.size()[0],1,attn_weights.size()[1]))\n",
        "      #apply to encoder states\n",
        "      attn_vec = torch.bmm(attn_weights,out)\n",
        "      attn_vec = attn_vec.view((attn_vec.size()[0],attn_vec.size()[2]))\n",
        "      #create input\n",
        "      inp = torch.cat((attn_vec,y,x[:,i,:]),1)\n",
        "      #dropout\n",
        "      inp = self.drop(inp)\n",
        "      #pass through generator\n",
        "      z,_ = self.dec(inp)\n",
        "      #expand to vocab\n",
        "      g = self.llayer(z)\n",
        "      gen[:,:,i] = g\n",
        "      i += 1\n",
        "    #rescale to temperature\n",
        "    gen = (gen - torch.max(gen,1)[0].unsqueeze(1).repeat(1,self.nvocab,1))/self.temp\n",
        "    return gen,kl\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fia2-qfw1z-9"
      },
      "source": [
        "#VAE with LSTM, style as linear layer training\n",
        "#Set seeds for reproducability\n",
        "torch.backends.cudnn.deterministic = True\n",
        "np.random.seed(100)\n",
        "torch.manual_seed(100)\n",
        "torch.cuda.manual_seed(100)\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "ind = np.array(author_labels)\n",
        "#choose which indices to use - two at a time\n",
        "a0 = np.where(ind==0)[0]\n",
        "a1 = np.where(ind==1)[0]\n",
        "ind[a0] = 0\n",
        "ind[a1] = 1\n",
        "avail_poems = np.array(r_authors_poem_line,dtype='object')[np.concatenate((a0,a1))]\n",
        "avail_ind = ind[np.concatenate((a0,a1))]\n",
        "#sequence length\n",
        "mlen = 15\n",
        "#Get vocab, labels, lengths, and numbered input for network\n",
        "vocab = create_vocab_dict(avail_poems,mincount=0)\n",
        "padded,lab,lengs = vnorm(avail_poems,vocab,avail_ind,mlen)\n",
        "#divide into training and validaiton\n",
        "fp = np.array(lab)\n",
        "_,rc = np.unique(fp,return_counts=True)\n",
        "cut = np.array(np.round(rc*0.8),dtype=int)\n",
        "w0 = np.where(fp==0)[0]\n",
        "w1 = np.where(fp==1)[0]\n",
        "np.random.shuffle(w0)\n",
        "np.random.shuffle(w1)\n",
        "trind =  np.concatenate((w0[0:cut[0]],w1[0:cut[1]]))\n",
        "vind = np.concatenate((w0[cut[0]:len(w0)],w1[cut[1]:len(w1)]))\n",
        "train_track = np.arange(len(trind))\n",
        "valid_track = np.arange(len(vind))\n",
        "lof = np.array(lengs)\n",
        "lengs = lof[trind]\n",
        "vlengs = lof[vind]\n",
        "input = torch.tensor(padded)[trind].to(device)\n",
        "validation = torch.tensor(padded)[vind].to(device)\n",
        "labels = torch.tensor(lab)[trind].to(device)\n",
        "vlabels = torch.tensor(lab)[vind].to(device)\n",
        "#Weighting to ignore gradient over padding and unk tokens\n",
        "weights = torch.ones(len(vocab.keys())).to(device)\n",
        "weights[3] = 0\n",
        "weights[0] = 0\n",
        "#initialize network,loss,optimizer\n",
        "net = LSTM_ATN_VAE_BD(300,100,2,300,100,1,len(vocab.keys()),mlen-1,drop=0.1,temp=10)\n",
        "loss_func = nn.CrossEntropyLoss(weight=weights,reduction='none')\n",
        "net = net.to(device)\n",
        "optimizer = torch.optim.Adam(net.parameters(),lr=0.0001)\n",
        "batch_size = 512\n",
        "trainloss = []\n",
        "trainkl = []\n",
        "validloss = []\n",
        "validkl = []\n",
        "#coefficients for KL annealing\n",
        "klcoef = np.concatenate((np.zeros(250),np.linspace(0,1,250),np.ones(9500)))\n",
        "i = 0\n",
        "while i < 4924:\n",
        "  #sample random minibatch\n",
        "  np.random.shuffle(train_track)\n",
        "  k = 0\n",
        "  lp = 0\n",
        "  klp = 0\n",
        "  while k < len(trind)//batch_size + 1:\n",
        "    #zero gradient\n",
        "    optimizer.zero_grad()\n",
        "    #get inputs\n",
        "    inp = input[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    les = lengs[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    oh = inp.long().to(device)\n",
        "    class_inp = one_hot(labels[train_track[k*batch_size:(k+1)*batch_size]],2).to(device)\n",
        "    #pass through network\n",
        "    gen,kl = net(inp,class_inp,les)\n",
        "    #record loss\n",
        "    rec_loss = loss_func(gen,oh[:,1:mlen])\n",
        "    mask = rec_loss != 0\n",
        "    lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "    klp += kl.item()\n",
        "    #backward gradient\n",
        "    loss = torch.mean(loss_func(gen,oh[:,1:mlen])) + kl*klcoef[i]\n",
        "    loss.backward()\n",
        "    #clip gradient\n",
        "    torch.nn.utils.clip_grad_norm_(net.parameters(),max_norm=1)\n",
        "    optimizer.step()\n",
        "    k += 1\n",
        "  trainloss.append(lp/len(input))\n",
        "  trainkl.append(klp/len(input))\n",
        "  #get validation loss\n",
        "  with torch.no_grad():\n",
        "    k = 0\n",
        "    while k < len(vind)//batch_size + 1:\n",
        "      inp = validation[valid_track[k*batch_size:(k+1)*batch_size]]\n",
        "      les = vlengs[valid_track[k*batch_size:(k+1)*batch_size]]\n",
        "      oh = inp.long().to(device)\n",
        "      class_inp = one_hot(vlabels[valid_track[k*batch_size:(k+1)*batch_size]],2).to(device)\n",
        "      gen,kl = net(inp,class_inp,les)\n",
        "      rec_loss = loss_func(gen,oh[:,1:mlen])\n",
        "      mask = rec_loss != 0\n",
        "      lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "      klp += kl.item()\n",
        "      k += 1\n",
        "    validloss.append(lp/len(validation))\n",
        "    validkl.append(klp/len(validation))\n",
        "    print(i,trainloss[-1],trainkl[-1],validloss[-1],validkl[-1])\n",
        "    i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNJNYugc6nYg"
      },
      "source": [
        "!pip3 install py-rouge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8ylCZCuDZKr"
      },
      "source": [
        "#getting BLEU and ROUGE scores \n",
        "import nltk\n",
        "import rouge\n",
        "nltk.download('punkt')\n",
        "apply_avg = True\n",
        "apply_best = False\n",
        "evaluator = rouge.Rouge(metrics=['rouge-n'],\n",
        "                           max_n=4,\n",
        "                           limit_length=True,\n",
        "                           length_limit=100,\n",
        "                           length_limit_type='words',\n",
        "                           apply_avg=apply_avg,\n",
        "                           apply_best=apply_best,\n",
        "                           alpha=0.5, # Default F1_score\n",
        "                           weight_factor=1.2,\n",
        "                           stemming=True)\n",
        "bleu_tref = []\n",
        "bleu_thyp = []\n",
        "bleu_vref = []\n",
        "bleu_vhyp = []\n",
        "rouge_tref = []\n",
        "rouge_thyp = []\n",
        "rouge_vref = []\n",
        "rouge_vhyp = []\n",
        "ke = list(vocab.keys())\n",
        "k = 0\n",
        "while k < len(input):\n",
        "  l = []\n",
        "  for j in input[k]:\n",
        "    if j.cpu().item() == 2:\n",
        "      pass\n",
        "    elif j.cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      l.append(ke[j.cpu().item()])\n",
        "  bleu_tref.append([l])\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(l):\n",
        "    if i == len(l) - 1:\n",
        "      rs += l[i]\n",
        "    else:\n",
        "      rs += l[i] + ' '\n",
        "    i += 1\n",
        "  rouge_tref.append(rs)\n",
        "  with torch.no_grad():\n",
        "    out,_ = net(input[k:k+1],one_hot(labels[k:k+1],2).to(device),lengs[k:k+1])\n",
        "  out = out.reshape((out.size()[1],-1))\n",
        "  sents = torch.max(out,0)[1]\n",
        "  gsen = []\n",
        "  p = 0\n",
        "  while p < len(sents):\n",
        "    if sents[p].cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      gsen.append(ke[sents[p].cpu().item()])\n",
        "    p += 1\n",
        "  bleu_thyp.append(gsen)\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(gsen):\n",
        "    if i == len(gsen) - 1:\n",
        "      rs += gsen[i]\n",
        "    else:\n",
        "      rs += gsen[i] + ' '\n",
        "    i += 1\n",
        "  rouge_thyp.append(rs)\n",
        "  k += 1\n",
        "k = 0\n",
        "while k < len(validation):\n",
        "  l = []\n",
        "  for j in validation[k]:\n",
        "    if j.cpu().item() == 2:\n",
        "      pass\n",
        "    elif j.cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      l.append(ke[j.cpu().item()])\n",
        "  bleu_vref.append([l])\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(l):\n",
        "    if i == len(l) - 1:\n",
        "      rs += l[i]\n",
        "    else:\n",
        "      rs += l[i] + ' '\n",
        "    i += 1\n",
        "  rouge_vref.append(rs)\n",
        "  with torch.no_grad():\n",
        "    out,_ = net(validation[k:k+1],one_hot(vlabels[k:k+1],2).to(device),vlengs[k:k+1])\n",
        "  out = out.reshape((out.size()[1],-1))\n",
        "  sents = torch.max(out,0)[1]\n",
        "  gsen = []\n",
        "  p = 0\n",
        "  while p < len(sents):\n",
        "    if sents[p].cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      gsen.append(ke[sents[p].cpu().item()])\n",
        "    p += 1\n",
        "  bleu_vhyp.append(gsen)\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(gsen):\n",
        "    if i == len(gsen) - 1:\n",
        "      rs += gsen[i]\n",
        "    else:\n",
        "      rs += gsen[i] + ' '\n",
        "    i += 1\n",
        "  rouge_vhyp.append(rs)\n",
        "  k += 1\n",
        "tscores = evaluator.get_scores(rouge_tref, rouge_thyp)\n",
        "vscores = evaluator.get_scores(rouge_vref, rouge_vhyp)\n",
        "print('BLEU Score Training')\n",
        "print(nltk.translate.bleu_score.corpus_bleu(bleu_tref,bleu_thyp))\n",
        "print('BLEU Score Validation')\n",
        "print(nltk.translate.bleu_score.corpus_bleu(bleu_vref,bleu_vhyp))\n",
        "print('ROUGE-1 Training')\n",
        "print(tscores['rouge-1']['f'])\n",
        "print('ROUGE-2 Training')\n",
        "print(tscores['rouge-2']['f'])\n",
        "print('ROUGE-1 Validation')\n",
        "print(vscores['rouge-1']['f'])\n",
        "print('ROUGE-2 Validation')\n",
        "print(vscores['rouge-2']['f'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOUm0IM3H4Fy"
      },
      "source": [
        "#Code to load saved ATN VAE BD Model\n",
        "torch.backends.cudnn.deterministic = True\n",
        "np.random.seed(100)\n",
        "torch.manual_seed(100)\n",
        "torch.cuda.manual_seed(100)\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "ind = np.array(author_labels)\n",
        "#Choose which labels we want to use - only two at a time\n",
        "a0 = np.where(ind==2)[0]\n",
        "a1 = np.where(ind==3)[0]\n",
        "ind[a0] = 0\n",
        "ind[a1] = 1\n",
        "avail_poems = np.array(r_authors_poem_line,dtype='object')[np.concatenate((a0,a1))]\n",
        "avail_ind = ind[np.concatenate((a0,a1))]\n",
        "#Sequence length\n",
        "mlen = 15\n",
        "#Get vocab, labels, lengths, and numbered input for network\n",
        "vocab = create_vocab_dict(avail_poems,mincount=0)\n",
        "padded,lab,lengs = vnorm(avail_poems,vocab,avail_ind,mlen)\n",
        "fp = np.array(lab)\n",
        "_,rc = np.unique(fp,return_counts=True)\n",
        "cut = np.array(np.round(rc*0.8),dtype=int)\n",
        "w0 = np.where(fp==0)[0]\n",
        "w1 = np.where(fp==1)[0]\n",
        "np.random.shuffle(w0)\n",
        "np.random.shuffle(w1)\n",
        "trind =  np.concatenate((w0[0:cut[0]],w1[0:cut[1]]))\n",
        "vind = np.concatenate((w0[cut[0]:len(w0)],w1[cut[1]:len(w1)]))\n",
        "#Divide data into training and validation sets\n",
        "train_track = np.arange(len(trind))\n",
        "valid_track = np.arange(len(vind))\n",
        "lof = np.array(lengs)\n",
        "lengs = lof[trind]\n",
        "vlengs = lof[vind]\n",
        "input = torch.tensor(padded)[trind].to(device)\n",
        "validation = torch.tensor(padded)[vind].to(device)\n",
        "labels = torch.tensor(lab)[trind].to(device)\n",
        "vlabels = torch.tensor(lab)[vind].to(device)\n",
        "#Weighting to ignore gradient over padding and unk tokens\n",
        "weights = torch.ones(len(vocab.keys())).to(device)\n",
        "weights[3] = 0\n",
        "weights[0] = 0\n",
        "net = LSTM_ATN_VAE_BD(300,100,2,300,100,1,len(vocab.keys()),mlen-1,drop=0.1,temp=10)\n",
        "loss_func = nn.CrossEntropyLoss(weight=weights,reduction='none')\n",
        "net = net.to(device)\n",
        "#change path to where model is saved. Make sure numbers match with chosen labels\n",
        "net.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/Thesis/ATN_VAE_BD_2_3.pt'))\n",
        "net.eval()\n",
        "batch_size=256\n",
        "lp = 0\n",
        "with torch.no_grad():\n",
        "  k = 0\n",
        "  while k < len(vind)//batch_size + 1:\n",
        "    inp = validation[valid_track[k*batch_size:(k+1)*batch_size]]\n",
        "    les = vlengs[valid_track[k*batch_size:(k+1)*batch_size]]\n",
        "    oh = inp.long().to(device)\n",
        "    class_inp = one_hot(vlabels[valid_track[k*batch_size:(k+1)*batch_size]],2).to(device)\n",
        "    gen,kl = net(inp,class_inp,les)\n",
        "    rec_loss = loss_func(gen,oh[:,1:mlen])\n",
        "    mask = rec_loss != 0\n",
        "    lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "    k += 1\n",
        "print(lp/len(validation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6V6LCReH46y"
      },
      "source": [
        "#Base classifier\n",
        "np.random.seed(100)\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "#term frequency matrix\n",
        "def tf(poems):\n",
        "  vocab = []\n",
        "  for p in poems:\n",
        "    for s in p:\n",
        "      for st in s: \n",
        "        if st not in vocab:\n",
        "          vocab.append(st)\n",
        "  mat_tf = np.zeros((len(poems),len(vocab)))\n",
        "  i = 0\n",
        "  while i < len(poems):\n",
        "    for line in poems[i]:\n",
        "      for word in line:\n",
        "        mat_tf[i,vocab.index(word)] += 1\n",
        "    i += 1\n",
        "  return mat_tf,vocab\n",
        "def to_mat(p,voc):\n",
        "  mat = np.zeros((len(p),len(voc)))\n",
        "  i = 0\n",
        "  for poem in p:\n",
        "    for line in poem:\n",
        "      for word in line:\n",
        "        if word in voc:\n",
        "          mat[i,voc.index(word)] += 1\n",
        "    i += 1\n",
        "  return mat\n",
        "mtf,avail_vocab = tf(avail_poems)\n",
        "plabels = np.array(avail_ind)\n",
        "#train classifier\n",
        "X_train,X_test,y_train,y_test = train_test_split(mtf,plabels,test_size=0.33,random_state=100,stratify=plabels)\n",
        "clf = LinearSVC(random_state=100)\n",
        "clf.fit(X_train,y_train)\n",
        "pred = clf.predict(X_test)\n",
        "print(len(np.where(pred==y_test)[0])/len(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7I1X1aLVeO3"
      },
      "source": [
        "#Refer to ATN VAE beam search - this is the same but adjusted for ATN BD VAE\n",
        "ke = list(vocab.keys())\n",
        "beam_width = 10\n",
        "real_poems = []\n",
        "transferred_poems = []\n",
        "sample_labels = []\n",
        "print(len(avail_poems))\n",
        "i = 0\n",
        "while i < len(avail_poems):\n",
        "  av = avail_poems[i]\n",
        "  real_poems.append(av)\n",
        "  sample_labels.append(avail_ind[i])\n",
        "  genpoem = []\n",
        "  for line in av:\n",
        "    if len(line) == 0:\n",
        "      pass\n",
        "    else:\n",
        "      curlab = one_hot([avail_ind[i]],2).to(device)\n",
        "      modlab = one_hot([1 - avail_ind[i]],2).to(device)\n",
        "      leng = []\n",
        "      a = []\n",
        "      a.append(vocab['<go>'])\n",
        "      for h in line:\n",
        "        if h in vocab:\n",
        "          a.append(vocab[h])\n",
        "        else:\n",
        "          a.append(vocab['<unk>'])\n",
        "      if len(a) > mlen-1:\n",
        "        a = a[0:mlen-1]\n",
        "        a.append(vocab['<eos>'])\n",
        "        leng.append(mlen)\n",
        "      else:\n",
        "        a.append(vocab['<eos>'])\n",
        "        car = len(a)\n",
        "        leng.append(car)\n",
        "        j = 0\n",
        "        while j < mlen-car:\n",
        "          a.append(vocab['<pad>'])\n",
        "          j += 1\n",
        "      with torch.no_grad():\n",
        "        x = torch.tensor(a).to(device).reshape((1,-1))\n",
        "        les = torch.tensor(leng)\n",
        "        x = net.embedding(x)\n",
        "        y = net.style_expand(curlab)\n",
        "        mody = net.style_expand(modlab)\n",
        "        ex = torch.cat((y.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "        ex = pack_padded_sequence(ex,les,batch_first=True,enforce_sorted=False)\n",
        "        out,(hz,_) = net.enc_z(ex)\n",
        "        out = pad_packed_sequence(out,batch_first=True,total_length=x.size()[1])[0]\n",
        "        z = torch.normal(torch.zeros((x.size()[0],net.out)),torch.ones((x.size()[0],net.out))).to(device)\n",
        "        best_embed = net.embedding(torch.tensor([2]).to(device))\n",
        "        gen = []\n",
        "        k = 0\n",
        "        while k < mlen-1:\n",
        "          if k == 0:\n",
        "            attn_weights = net.softmax(net.attn_reduce(net.relu(net.attn_enc(out) + net.attn_hid(z.unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "            attn_weights = attn_weights.view((attn_weights.size()[0],1,attn_weights.size()[1]))\n",
        "            attn_vec = torch.bmm(attn_weights,out)\n",
        "            attn_vec = attn_vec.view((attn_vec.size()[0],attn_vec.size()[2]))\n",
        "            inp = torch.cat((attn_vec,mody,x[:,k,:]),1)\n",
        "            z,_ = net.dec(inp)\n",
        "            ou = net.llayer(z)\n",
        "            z = z.repeat(beam_width,1)\n",
        "            out = out.repeat(beam_width,1,1)\n",
        "            ou = torch.nn.functional.softmax(ou.reshape((-1)),dim=0)\n",
        "            bind = torch.argsort(ou,descending=True)[0:beam_width]\n",
        "            ip = net.embedding(bind)\n",
        "            prob = ou[bind]\n",
        "            ct = 0\n",
        "            while ct < len(bind):\n",
        "              gen.append([ke[bind[ct].cpu().item()]])\n",
        "              ct += 1\n",
        "          else:\n",
        "            attn_weights = net.softmax(net.attn_reduce(net.relu(net.attn_enc(out) + net.attn_hid(z.unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "            attn_weights = attn_weights.view((attn_weights.size()[0],1,attn_weights.size()[1]))\n",
        "            attn_vec = torch.bmm(attn_weights,out)\n",
        "            attn_vec = attn_vec.view((attn_vec.size()[0],attn_vec.size()[2]))\n",
        "            inp = torch.cat((attn_vec,mody.repeat(beam_width,1),ip),1)\n",
        "            z,_ = net.dec(inp)\n",
        "            ou = net.llayer(z)\n",
        "            ou = torch.nn.functional.softmax(ou,dim=1)\n",
        "            aval,aind = torch.sort(ou,dim=1,descending=True)\n",
        "            aval = aval[:,0:beam_width]\n",
        "            aind = aind[:,0:beam_width]\n",
        "            aval = aval*(prob.unsqueeze(0).repeat(beam_width,1))\n",
        "            aval = aval.reshape((beam_width**2))\n",
        "            bind = torch.argsort(aval,descending=True)[0:beam_width]\n",
        "            prob = aval[bind]\n",
        "            ip = torch.zeros((beam_width,x.size()[2])).to(device)\n",
        "            ct = 0\n",
        "            ge = []\n",
        "            while ct < len(bind):\n",
        "              xind = bind[ct].cpu().item()//beam_width\n",
        "              yind = bind[ct].cpu().item()%beam_width\n",
        "              ip[ct] = net.embedding(aind[xind,yind])\n",
        "              ge.append(gen[xind] + [ke[aind[xind,yind].cpu().item()]])\n",
        "              ct += 1\n",
        "            gen = ge.copy()\n",
        "          k += 1\n",
        "      genpoem.append(gen)\n",
        "  l = 0\n",
        "  rp = []\n",
        "  while l < len(genpoem):\n",
        "    gp = genpoem[l][0]\n",
        "    rl = []\n",
        "    for word in gp:\n",
        "      if word in ['<pad>', '<unk>', '<go>']:\n",
        "        pass\n",
        "      elif word == '<eos>':\n",
        "        break\n",
        "      else:\n",
        "        rl.append(word)\n",
        "    rp.append(rl)\n",
        "    l += 1\n",
        "  transferred_poems.append(rp)\n",
        "  print(i)\n",
        "  i += 1\n",
        "i = 0\n",
        "avchange = 0\n",
        "better = np.zeros(len(real_poems))\n",
        "tclass = np.zeros(len(real_poems))\n",
        "while i < len(real_poems):\n",
        "  rlab = sample_labels[i]\n",
        "  tmat = to_mat([real_poems[i]] + [transferred_poems[i]],avail_vocab)\n",
        "  df = clf.decision_function(tmat)\n",
        "  pred = clf.predict(tmat)\n",
        "  if rlab == 0:\n",
        "    avchange += (df[1] - df[0])/np.abs(df[0])\n",
        "    if pred[1] == 1:\n",
        "      tclass[i] = 1\n",
        "  else:\n",
        "    avchange += (df[0] - df[1])/np.abs(df[0])\n",
        "    if pred[1] == 0:\n",
        "      tclass[i] = 1\n",
        "  i += 1\n",
        "print('Style Transfer Intensity')\n",
        "print(avchange/i)\n",
        "print('Classification Accuracy')\n",
        "print(np.sum(tclass)/len(tclass))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siVYqthucVAq"
      },
      "source": [
        "#try transferring various poems\n",
        "sp = np.array(sample_labels)\n",
        "tc = np.array(tclass)\n",
        "print(np.where(tclass==0)[0])\n",
        "print(np.where(tclass==1)[0])\n",
        "print(np.where(sp==0)[0])\n",
        "print(np.where(sp==1)[0])\n",
        "ind = 77\n",
        "print(tclass[ind])\n",
        "print('Real Poem:')\n",
        "for r in real_poems[ind]:\n",
        "  st = ''\n",
        "  for word in r:\n",
        "    st += word + ' '\n",
        "  print(st)\n",
        "print('Transferred Poem:')\n",
        "for r in transferred_poems[ind]:\n",
        "  st = ''\n",
        "  for word in r:\n",
        "    st += word + ' '\n",
        "  print(st)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n31c7Htf03-s"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np \n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "device = torch.device('cuda:0')\n",
        "#Cross aligned AE with LSTM, style as linear layer \n",
        "class LSTM_CAE(nn.Module):\n",
        "  def __init__(self, input_length, num_classes, hidden_length,layers,vocab_length, gen_length,temp):\n",
        "    super(LSTM_CAE,self).__init__()\n",
        "    #number of classes\n",
        "    self.numclasses = num_classes\n",
        "    #style information layer\n",
        "    self.style_layer = nn.Linear(num_classes,hidden_length)\n",
        "    #generation length\n",
        "    self.genlen = gen_length\n",
        "    #input length\n",
        "    self.inp = input_length\n",
        "    #vocab length\n",
        "    self.nvocab = vocab_length\n",
        "    #encoder\n",
        "    self.enc = nn.LSTM(input_length+hidden_length,hidden_length,layers,batch_first=True)\n",
        "    #generator\n",
        "    self.dec = nn.LSTMCell(input_length+2*hidden_length,input_length)\n",
        "    #word embedding\n",
        "    self.embedding = nn.Embedding(vocab_length,input_length, padding_idx=0)\n",
        "    #linear to expand to vocab size\n",
        "    self.llayer = nn.Linear(input_length,vocab_length)\n",
        "    #number of layers\n",
        "    self.numlayers = layers\n",
        "    #temperature\n",
        "    self.temp = temp\n",
        "  def forward(self,x,y,les):\n",
        "    #real labels\n",
        "    oy = self.style_layer(one_hot(y,2).to(device))\n",
        "    #transferred labels\n",
        "    mody = self.style_layer(one_hot(1-y,2).to(device))\n",
        "    #get word embeddings\n",
        "    x = self.embedding(x)\n",
        "    #pass through encoder\n",
        "    ex = torch.cat((oy.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "    ex = pack_padded_sequence(ex,les,batch_first=True,enforce_sorted=False)\n",
        "    _,(henc,_) = self.enc(ex)\n",
        "    henc = henc.view((henc.size()[1],henc.size()[2]*self.numlayers))\n",
        "    #real and transferred hidden states - for discriminator\n",
        "    gen_fake = torch.zeros((x.size()[0],self.genlen,self.inp)).to(device)\n",
        "    gen_real = torch.zeros((x.size()[0],self.genlen,self.inp)).to(device)\n",
        "    #generated words for reconstruction loss\n",
        "    gen = torch.zeros((x.size()[0],self.nvocab,self.genlen)).to(device)\n",
        "    #iterate over generation length\n",
        "    i = 0\n",
        "    while i < self.genlen:\n",
        "      #real input\n",
        "      inp1 = torch.cat((henc,oy,x[:,i,:]),1)\n",
        "      #transferred input\n",
        "      if i == 0:\n",
        "        inp2 = torch.cat((henc,mody,x[:,0,:]),1)\n",
        "      else:\n",
        "        inp2 = torch.cat((henc,mody,all_embed),1)\n",
        "      #pass through generator\n",
        "      ip = torch.cat((inp1,inp2),0)\n",
        "      z,_ = self.dec(ip)\n",
        "      #store hidden states for discriminator\n",
        "      cut = int(len(z)/2)\n",
        "      gen_real[:,i,:] = z[0:cut]\n",
        "      gen_fake[:,i,:] = z[cut:len(z)]\n",
        "      #expand to vocab length\n",
        "      kp = self.llayer(z)\n",
        "      #rescale\n",
        "      kp = kp - torch.max(kp,dim=1)[0].unsqueeze(1).repeat(1,kp.size()[1])\n",
        "      #store distribution over vocab for reconstruction\n",
        "      gen[:,:,i] = kp[0:cut]\n",
        "      #get word output for transferred samples as described in paper - weighted average over distribution\n",
        "      su = torch.sum(torch.exp(kp[cut:len(kp)]/self.temp),axis=1)\n",
        "      softmax = (torch.exp(kp[cut:len(kp)]/self.temp).T/(su)).T\n",
        "      ta = torch.arange(self.nvocab).to(device)\n",
        "      all_embed = self.embedding(ta)\n",
        "      all_embed = softmax@all_embed\n",
        "      i += 1\n",
        "    return gen,gen_real,gen_fake\n",
        "#discriminator\n",
        "class Disc(nn.Module):\n",
        "  def __init__(self, input_length,disc_hidden_length):\n",
        "    super(Disc,self).__init__()\n",
        "    #bidirectional LSTM\n",
        "    self.disc = nn.LSTM(input_length,disc_hidden_length,batch_first=True,bidirectional=True)\n",
        "    #linear layer to reduce - two dimensions with 1=real,0=fake\n",
        "    self.disc_linear = nn.Linear(disc_hidden_length*2,2)\n",
        "  def forward(self,disc_store):\n",
        "    _,(hid,_) = self.disc(disc_store)\n",
        "    hid = hid.reshape((hid.size()[1],hid.size()[2]*2))\n",
        "    hid = self.disc_linear(hid)\n",
        "    return hid\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlBVh25_06Bp"
      },
      "source": [
        "#CAE with LSTM, style as linear layer training\n",
        "#Set seeds for deterministic \n",
        "torch.backends.cudnn.deterministic = True\n",
        "np.random.seed(100)\n",
        "torch.manual_seed(100)\n",
        "torch.cuda.manual_seed(100)\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "#choose labels we want - two at a time\n",
        "ind = np.array(author_labels)\n",
        "a0 = np.where(ind==0)[0]\n",
        "a1 = np.where(ind==1)[0]\n",
        "ind[a0] = 0\n",
        "ind[a1] = 1\n",
        "avail_poems = np.array(r_authors_poem_line,dtype='object')[np.concatenate((a0,a1))]\n",
        "avail_ind = ind[np.concatenate((a0,a1))]\n",
        "#Sequence length\n",
        "mlen = 15\n",
        "#Get vocab, labels, lengths, and numbered input for network\n",
        "vocab = create_vocab_dict(avail_poems,mincount=0)\n",
        "padded,lab,lengs = vnorm(avail_poems,vocab,avail_ind,mlen)\n",
        "#divide into training and validation sets\n",
        "fp = np.array(lab)\n",
        "_,rc = np.unique(fp,return_counts=True)\n",
        "cut = np.array(np.round(rc*0.8),dtype=int)\n",
        "w0 = np.where(fp==0)[0]\n",
        "w1 = np.where(fp==1)[0]\n",
        "np.random.shuffle(w0)\n",
        "np.random.shuffle(w1)\n",
        "trind =  np.concatenate((w0[0:cut[0]],w1[0:cut[1]]))\n",
        "vind = np.concatenate((w0[cut[0]:len(w0)],w1[cut[1]:len(w1)]))\n",
        "train_track = np.arange(len(trind))\n",
        "valid_track = np.arange(len(vind))\n",
        "lof = np.array(lengs)\n",
        "lengs = lof[trind]\n",
        "vlengs = lof[vind]\n",
        "input = torch.tensor(padded)[trind].to(device)\n",
        "validation = torch.tensor(padded)[vind].to(device)\n",
        "labels = torch.tensor(lab)[trind].to(device)\n",
        "vlabels = torch.tensor(lab)[vind].to(device)\n",
        "#Weighting to ignore gradient over padding and unk tokens\n",
        "weights = torch.ones(len(vocab.keys())).to(device)\n",
        "weights[3] = 0\n",
        "weights[0] = 0\n",
        "#initialize network and discriminator for 0 and 1, loss, and three separate optimizers\n",
        "net = LSTM_CAE(300,2,300,1,len(vocab.keys()),mlen-1,10)\n",
        "disc_0 = Disc(300,100)\n",
        "disc_1 = Disc(300,100)\n",
        "loss_func = nn.CrossEntropyLoss(weight=weights,reduction='none')\n",
        "lf2 = nn.CrossEntropyLoss(reduction='mean')\n",
        "net = net.to(device)\n",
        "disc_0 = disc_0.to(device)\n",
        "disc_1 = disc_1.to(device)\n",
        "opt1 = torch.optim.Adam(net.parameters(),lr=0.0001)\n",
        "opt2 = torch.optim.Adam(disc_0.parameters(),lr=0.0001)\n",
        "opt3 = torch.optim.Adam(disc_1.parameters(),lr=0.0001)\n",
        "optimizer = [opt3,opt2,opt1]\n",
        "models = [disc_0,disc_1,net]\n",
        "trainloss = []\n",
        "traindisc = []\n",
        "valloss = []\n",
        "td = []\n",
        "batch_size=512\n",
        "i = 0\n",
        "while i < 3000:\n",
        "  #sample random minibatch\n",
        "  np.random.shuffle(train_track)\n",
        "  k = 0\n",
        "  lp = 0\n",
        "  klp = 0\n",
        "  while k < len(trind)//batch_size + 1:\n",
        "    #get inputs\n",
        "    inp = input[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    les = lengs[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    oh = inp[:,1:mlen].long().to(device)\n",
        "    curlab = labels[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    #pass through network\n",
        "    gen,gen_real,gen_fake = net(inp,curlab,les)\n",
        "    #figure out where labels are 0 and 1\n",
        "    zero_labels = torch.where(curlab==0)[0]\n",
        "    one_labels = torch.where(curlab==1)[0]\n",
        "    #Three possibilities - only 0,only 1, both\n",
        "    if len(zero_labels)==0 and len(one_labels) > 0:\n",
        "      #discriminator outputs\n",
        "      out0 = disc_0(gen_real)\n",
        "      out1 = disc_1(gen_fake)\n",
        "      #labels for discriminators\n",
        "      lab0 = torch.ones(len(gen_real)).long().to(device)\n",
        "      lab1 = torch.zeros(len(gen_fake)).long().to(device)\n",
        "      #output to check how well fake fools discriminator\n",
        "      zero_g = None\n",
        "      one_g = disc_1(gen_fake)\n",
        "      #labels for fake generator\n",
        "      lab0_g = None\n",
        "      lab1_g = torch.ones(len(gen_fake)).long().to(device)\n",
        "    elif len(one_labels)==0 and len(zero_labels) > 0:\n",
        "      #discriminator outputs\n",
        "      out0 = disc_0(gen_fake)\n",
        "      out1 = disc_1(gen_real)\n",
        "      #labels for discriminators\n",
        "      lab0 = torch.ones(len(gen_fake)).long().to(device)\n",
        "      lab1 = torch.zeros(len(gen_real)).long().to(device)\n",
        "      #output to check how well fake fools discriminator\n",
        "      zero_g = disc_0(gen_fake)\n",
        "      one_g = None\n",
        "      #labels for fake generator\n",
        "      lab1_g = None\n",
        "      lab0_g = torch.ones(len(gen_fake)).long().to(device)\n",
        "    else:\n",
        "      #all inputs for zero discriminator\n",
        "      g0 = torch.cat((gen_real[zero_labels],gen_fake[one_labels]),0)\n",
        "      #all inputs for one discriminator\n",
        "      g1 = torch.cat((gen_real[one_labels],gen_fake[zero_labels]),0)\n",
        "      #discriminator outputs\n",
        "      out0 = disc_0(g0)\n",
        "      out1 = disc_1(g1)\n",
        "      #discriminator labels\n",
        "      lab0 = torch.cat((torch.ones(len(zero_labels)),torch.zeros(len(one_labels))),0).long().to(device)\n",
        "      lab1 = torch.cat((torch.ones(len(one_labels)),torch.zeros(len(zero_labels))),0).long().to(device)\n",
        "      #output to check how well fake fools discriminator\n",
        "      zero_g = disc_0(gen_fake[one_labels])\n",
        "      one_g = disc_1(gen_fake[zero_labels])\n",
        "      #labels for fake generator\n",
        "      lab0_g = torch.ones(len(one_labels)).long().to(device)\n",
        "      lab1_g = torch.ones(len(zero_labels)).long().to(device)\n",
        "    #calculate loss of discriminators\n",
        "    l0 = lf2(out0,lab0)\n",
        "    l1 = lf2(out1,lab1)\n",
        "    #calculate adversarial loss - does generator fool discriminator\n",
        "    if zero_g is not None:\n",
        "      l0_g = lf2(zero_g,lab0_g)\n",
        "    else:\n",
        "      l0_g = 0\n",
        "    if one_g is not None:\n",
        "      l1_g = lf2(one_g,lab1_g)\n",
        "    else:\n",
        "      l1_g = 0\n",
        "    #calculate reconstruction loss\n",
        "    rec_loss = loss_func(gen,oh)\n",
        "    loss = torch.mean(rec_loss) + (l0_g + l1_g)\n",
        "    losses = [l0,l1,loss]\n",
        "    #backward gradient over three networks\n",
        "    g = 0\n",
        "    while g < 3:\n",
        "      optimizer[g].zero_grad()\n",
        "      losses[g].backward(retain_graph=True)\n",
        "      torch.nn.utils.clip_grad_norm_(models[g].parameters(),max_norm=1)\n",
        "      g += 1\n",
        "    g = 0\n",
        "    while g < 3:\n",
        "      optimizer[g].step()\n",
        "      g += 1\n",
        "    #record loss\n",
        "    mask = rec_loss != 0\n",
        "    lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "    k += 1\n",
        "  trainloss.append(lp/len(input))\n",
        "  #measure validation loss - here we generate without cross-alignment\n",
        "  with torch.no_grad():\n",
        "    k = 0\n",
        "    lp = 0\n",
        "    while k < len(validation)//256:\n",
        "      inp = validation[k*256:(k+1)*256]\n",
        "      oh = inp[:,1:mlen].long()\n",
        "      class_inp = one_hot(vlabels[k*256:(k+1)*256],2).to(device)\n",
        "      le = vlengs[k*256:(k+1)*256]\n",
        "      y = net.style_layer(class_inp)\n",
        "      x = net.embedding(inp)\n",
        "      ex = torch.cat((y.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "      ex = pack_padded_sequence(ex,le,batch_first=True,enforce_sorted=False)\n",
        "      _,(henc,_) = net.enc(ex)\n",
        "      henc = henc.view((henc.size()[1],henc.size()[2]*net.numlayers))\n",
        "      gen = torch.zeros((henc.size()[0],net.nvocab,net.genlen)).to(device)\n",
        "      p = 0\n",
        "      while p < net.genlen:\n",
        "        ip = torch.cat((henc,y,x[:,p,:]),1)\n",
        "        kp,_ = net.dec(ip)\n",
        "        kp = net.llayer(kp)\n",
        "        gen[:,:,p] = kp\n",
        "        p += 1\n",
        "      rec_loss = loss_func(gen,oh)\n",
        "      mask = rec_loss != 0\n",
        "      lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "      k += 1\n",
        "  valloss.append(lp/len(validation))  \n",
        "  print(i,trainloss[-1],valloss[-1])\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulDq5Ic7enN3"
      },
      "source": [
        "!pip install py-rouge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYIAj7nMZm3x"
      },
      "source": [
        "#evaluating BLEU and ROUGE - difference here is instead of using original network we have to manually compute (similar to validation loss)\n",
        "import nltk\n",
        "import rouge\n",
        "nltk.download('punkt')\n",
        "apply_avg = True\n",
        "apply_best = False\n",
        "evaluator = rouge.Rouge(metrics=['rouge-n'],\n",
        "                           max_n=4,\n",
        "                           limit_length=True,\n",
        "                           length_limit=100,\n",
        "                           length_limit_type='words',\n",
        "                           apply_avg=apply_avg,\n",
        "                           apply_best=apply_best,\n",
        "                           alpha=0.5, # Default F1_score\n",
        "                           weight_factor=1.2,\n",
        "                           stemming=True)\n",
        "def eval_inp(inp,class_inp,le):\n",
        "  y = net.style_layer(class_inp)\n",
        "  x = net.embedding(inp)\n",
        "  ex = torch.cat((y.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "  ex = pack_padded_sequence(ex,le,batch_first=True,enforce_sorted=False)\n",
        "  _,(henc,_) = net.enc(ex)\n",
        "  henc = henc.view((henc.size()[1],henc.size()[2]*net.numlayers))\n",
        "  gen = torch.zeros((henc.size()[0],net.nvocab,net.genlen)).to(device)\n",
        "  p = 0\n",
        "  while p < net.genlen:\n",
        "    ip = torch.cat((henc,y,x[:,p,:]),1)\n",
        "    kp,_ = net.dec(ip)\n",
        "    kp = net.llayer(kp)\n",
        "    gen[:,:,p] = kp\n",
        "    p += 1\n",
        "  return gen\n",
        "bleu_tref = []\n",
        "bleu_thyp = []\n",
        "bleu_vref = []\n",
        "bleu_vhyp = []\n",
        "rouge_tref = []\n",
        "rouge_thyp = []\n",
        "rouge_vref = []\n",
        "rouge_vhyp = []\n",
        "ke = list(vocab.keys())\n",
        "k = 0\n",
        "while k < len(input):\n",
        "  l = []\n",
        "  for j in input[k]:\n",
        "    if j.cpu().item() == 2:\n",
        "      pass\n",
        "    elif j.cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      l.append(ke[j.cpu().item()])\n",
        "  bleu_tref.append([l])\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(l):\n",
        "    if i == len(l) - 1:\n",
        "      rs += l[i]\n",
        "    else:\n",
        "      rs += l[i] + ' '\n",
        "    i += 1\n",
        "  rouge_tref.append(rs)\n",
        "  with torch.no_grad():\n",
        "    out = eval_inp(input[k:k+1],one_hot(labels[k:k+1],2).to(device),lengs[k:k+1])\n",
        "  out = out.reshape((out.size()[1],-1))\n",
        "  sents = torch.max(out,0)[1]\n",
        "  gsen = []\n",
        "  p = 0\n",
        "  while p < len(sents):\n",
        "    if sents[p].cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      gsen.append(ke[sents[p].cpu().item()])\n",
        "    p += 1\n",
        "  bleu_thyp.append(gsen)\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(gsen):\n",
        "    if i == len(gsen) - 1:\n",
        "      rs += gsen[i]\n",
        "    else:\n",
        "      rs += gsen[i] + ' '\n",
        "    i += 1\n",
        "  rouge_thyp.append(rs)\n",
        "  k += 1\n",
        "k = 0\n",
        "while k < len(validation):\n",
        "  l = []\n",
        "  for j in validation[k]:\n",
        "    if j.cpu().item() == 2:\n",
        "      pass\n",
        "    elif j.cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      l.append(ke[j.cpu().item()])\n",
        "  bleu_vref.append([l])\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(l):\n",
        "    if i == len(l) - 1:\n",
        "      rs += l[i]\n",
        "    else:\n",
        "      rs += l[i] + ' '\n",
        "    i += 1\n",
        "  rouge_vref.append(rs)\n",
        "  out = eval_inp(validation[k:k+1],one_hot(vlabels[k:k+1],2).to(device),vlengs[k:k+1])\n",
        "  out = out.reshape((out.size()[1],-1))\n",
        "  sents = torch.max(out,0)[1]\n",
        "  gsen = []\n",
        "  p = 0\n",
        "  while p < len(sents):\n",
        "    if sents[p].cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      gsen.append(ke[sents[p].cpu().item()])\n",
        "    p += 1\n",
        "  bleu_vhyp.append(gsen)\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(gsen):\n",
        "    if i == len(gsen) - 1:\n",
        "      rs += gsen[i]\n",
        "    else:\n",
        "      rs += gsen[i] + ' '\n",
        "    i += 1\n",
        "  rouge_vhyp.append(rs)\n",
        "  k += 1\n",
        "tscores = evaluator.get_scores(rouge_tref, rouge_thyp)\n",
        "vscores = evaluator.get_scores(rouge_vref, rouge_vhyp)\n",
        "print('BLEU Score Training')\n",
        "print(nltk.translate.bleu_score.corpus_bleu(bleu_tref,bleu_thyp))\n",
        "print('BLEU Score Validation')\n",
        "print(nltk.translate.bleu_score.corpus_bleu(bleu_vref,bleu_vhyp))\n",
        "print('ROUGE-1 Training')\n",
        "print(tscores['rouge-1']['f'])\n",
        "print('ROUGE-2 Training')\n",
        "print(tscores['rouge-2']['f'])\n",
        "print('ROUGE-1 Validation')\n",
        "print(vscores['rouge-1']['f'])\n",
        "print('ROUGE-2 Validation')\n",
        "print(vscores['rouge-2']['f'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgqYRsoVN5Hm"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np \n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "device = torch.device('cuda:0')\n",
        "#Cross aligned AE with Bidirectional LSTM, style as linear layer \n",
        "class LSTM_CAE_BD(nn.Module):\n",
        "  def __init__(self, input_length, num_classes, hidden_length,layers,vocab_length, gen_length,temp):\n",
        "    super(LSTM_CAE_BD,self).__init__()\n",
        "    #number of classes\n",
        "    self.numclasses = num_classes\n",
        "    #linear for style\n",
        "    self.style_layer = nn.Linear(num_classes,hidden_length)\n",
        "    #generation length\n",
        "    self.genlen = gen_length\n",
        "    #embedding dim\n",
        "    self.inp = input_length\n",
        "    #vocab length\n",
        "    self.nvocab = vocab_length\n",
        "    #encoder\n",
        "    self.enc = nn.LSTM(input_length+hidden_length,hidden_length,layers,batch_first=True,bidirectional=True)\n",
        "    #generator\n",
        "    self.dec = nn.LSTMCell(input_length+3*hidden_length,input_length)\n",
        "    #word embedding\n",
        "    self.embedding = nn.Embedding(vocab_length,input_length, padding_idx=0)\n",
        "    #linear to expand to vocab length\n",
        "    self.llayer = nn.Linear(input_length,vocab_length)\n",
        "    #number of layers\n",
        "    self.numlayers = layers\n",
        "    #temperature\n",
        "    self.temp = temp\n",
        "  def forward(self,x,y,les):\n",
        "    #real labels\n",
        "    oy = self.style_layer(one_hot(y,2).to(device))\n",
        "    #transferred labels\n",
        "    mody = self.style_layer(one_hot(1-y,2).to(device))\n",
        "    #get word embeddings\n",
        "    x = self.embedding(x)\n",
        "    #pass through encoder\n",
        "    ex = torch.cat((oy.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "    ex = pack_padded_sequence(ex,les,batch_first=True,enforce_sorted=False)\n",
        "    _,(henc,_) = self.enc(ex)\n",
        "    henc = henc.view((henc.size()[1],henc.size()[2]*2*self.numlayers))\n",
        "    #inputs to discriminator - transferred and real\n",
        "    gen_fake = torch.zeros((x.size()[0],self.genlen,self.inp)).to(device)\n",
        "    gen_real = torch.zeros((x.size()[0],self.genlen,self.inp)).to(device)\n",
        "    #distribution over vocab length for reconstruction loss\n",
        "    gen = torch.zeros((x.size()[0],self.nvocab,self.genlen)).to(device)\n",
        "    i = 0\n",
        "    while i < self.genlen:\n",
        "      #real input\n",
        "      inp1 = torch.cat((henc,oy,x[:,i,:]),1)\n",
        "      #transferred input\n",
        "      if i == 0:\n",
        "        inp2 = torch.cat((henc,mody,x[:,0,:]),1)\n",
        "      else:\n",
        "        inp2 = torch.cat((henc,mody,all_embed),1)\n",
        "      #pass through generator\n",
        "      ip = torch.cat((inp1,inp2),0)\n",
        "      z,_ = self.dec(ip)\n",
        "      #store states for discriminator\n",
        "      cut = int(len(z)/2)\n",
        "      gen_real[:,i,:] = z[0:cut]\n",
        "      gen_fake[:,i,:] = z[cut:len(z)]\n",
        "      #expand to vocab length\n",
        "      kp = self.llayer(z)\n",
        "      #rescale\n",
        "      kp = (kp - torch.max(kp,dim=1)[0].unsqueeze(1).repeat(1,kp.size()[1]))\n",
        "      #store distribution over vocab\n",
        "      gen[:,:,i] = kp[0:cut]\n",
        "      #get words for transferred - weighted average over distribution\n",
        "      su = torch.sum(torch.exp(kp[cut:len(kp)]/self.temp),axis=1)\n",
        "      softmax = (torch.exp(kp[cut:len(kp)]/self.temp).T/(su)).T\n",
        "      ta = torch.arange(self.nvocab).to(device)\n",
        "      all_embed = self.embedding(ta)\n",
        "      all_embed = softmax@all_embed\n",
        "      i += 1\n",
        "    return gen,gen_fake,gen_real\n",
        "#discriminator\n",
        "class Disc(nn.Module):\n",
        "  def __init__(self, input_length,disc_hidden_length):\n",
        "    super(Disc,self).__init__()\n",
        "    #bidirectional LSTM\n",
        "    self.disc = nn.LSTM(input_length,disc_hidden_length,batch_first=True,bidirectional=True)\n",
        "    #linear layer to get 2d output - 1=real,0=transferred\n",
        "    self.disc_linear = nn.Linear(disc_hidden_length*2,2)\n",
        "  def forward(self,disc_store):\n",
        "    _,(hid,_) = self.disc(disc_store)\n",
        "    hid = hid.reshape((hid.size()[1],hid.size()[2]*2))\n",
        "    hid = self.disc_linear(hid)\n",
        "    return hid\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVpugBHBN5dv"
      },
      "source": [
        "#CAE with bidirectional LSTM, style as linear layer training\n",
        "#set seeds for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "np.random.seed(100)\n",
        "torch.manual_seed(100)\n",
        "torch.cuda.manual_seed(100)\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "ind = np.array(author_labels)\n",
        "#choose which labels to use - two at a time\n",
        "a0 = np.where(ind==0)[0]\n",
        "a1 = np.where(ind==1)[0]\n",
        "ind[a0] = 0\n",
        "ind[a1] = 1\n",
        "avail_poems = np.array(r_authors_poem_line,dtype='object')[np.concatenate((a0,a1))]\n",
        "avail_ind = ind[np.concatenate((a0,a1))]\n",
        "#Sequence length\n",
        "mlen = 15\n",
        "#Get vocab, labels, lengths, and numbered input for network\n",
        "vocab = create_vocab_dict(avail_poems,mincount=0)\n",
        "padded,lab,lengs = vnorm(avail_poems,vocab,avail_ind,mlen)\n",
        "#divide into training and validation\n",
        "fp = np.array(lab)\n",
        "_,rc = np.unique(fp,return_counts=True)\n",
        "cut = np.array(np.round(rc*0.8),dtype=int)\n",
        "w0 = np.where(fp==0)[0]\n",
        "w1 = np.where(fp==1)[0]\n",
        "np.random.shuffle(w0)\n",
        "np.random.shuffle(w1)\n",
        "trind =  np.concatenate((w0[0:cut[0]],w1[0:cut[1]]))\n",
        "vind = np.concatenate((w0[cut[0]:len(w0)],w1[cut[1]:len(w1)]))\n",
        "train_track = np.arange(len(trind))\n",
        "valid_track = np.arange(len(vind))\n",
        "lof = np.array(lengs)\n",
        "lengs = lof[trind]\n",
        "vlengs = lof[vind]\n",
        "input = torch.tensor(padded)[trind].to(device)\n",
        "validation = torch.tensor(padded)[vind].to(device)\n",
        "labels = torch.tensor(lab)[trind].to(device)\n",
        "vlabels = torch.tensor(lab)[vind].to(device)\n",
        "#weighting to ignore gradient over padding and unk tokens\n",
        "weights = torch.ones(len(vocab.keys())).to(device)\n",
        "weights[3] = 0\n",
        "weights[0] = 0\n",
        "#initialize network, discriminators, losses, and optimizer\n",
        "net = LSTM_CAE_BD(300,2,300,1,len(vocab.keys()),mlen-1,10)\n",
        "disc_0 = Disc(300,100)\n",
        "disc_1 = Disc(300,100)\n",
        "loss_func = nn.CrossEntropyLoss(weight=weights,reduction='none')\n",
        "lf2 = nn.CrossEntropyLoss(reduction='mean')\n",
        "net = net.to(device)\n",
        "disc_0 = disc_0.to(device)\n",
        "disc_1 = disc_1.to(device)\n",
        "opt1 = torch.optim.Adam(net.parameters(),lr=0.0001)\n",
        "opt2 = torch.optim.Adam(disc_0.parameters(),lr=0.0001)\n",
        "opt3 = torch.optim.Adam(disc_1.parameters(),lr=0.0001)\n",
        "optimizer = [opt3,opt2,opt1]\n",
        "models = [disc_0,disc_1,net]\n",
        "trainloss = []\n",
        "traindisc = []\n",
        "valloss = []\n",
        "td = []\n",
        "batch_size=256\n",
        "i = 0\n",
        "while i < 1500:\n",
        "  #sample ranodm minibatch\n",
        "  np.random.shuffle(train_track)\n",
        "  k = 0\n",
        "  lp = 0\n",
        "  klp = 0\n",
        "  while k < len(trind)//batch_size + 1:\n",
        "    #gets inputs\n",
        "    inp = input[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    les = lengs[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    oh = inp[:,1:mlen].long().to(device)\n",
        "    curlab = labels[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    #pass through networks\n",
        "    gen,gen_real,gen_fake = net(inp,curlab,les)\n",
        "    #find where 0 and 1 labels are\n",
        "    zero_labels = torch.where(curlab==0)[0]\n",
        "    one_labels = torch.where(curlab==1)[0]\n",
        "    #three possibilities - all zeros, all ones, both\n",
        "    if len(zero_labels)==0 and len(one_labels) > 0:\n",
        "      #discriminator output\n",
        "      out0 = disc_0(gen_real)\n",
        "      out1 = disc_1(gen_fake)\n",
        "      #discriminator labels\n",
        "      lab0 = torch.ones(len(gen_real)).long().to(device)\n",
        "      lab1 = torch.zeros(len(gen_fake)).long().to(device)\n",
        "      #output to check how well fake fools discriminator\n",
        "      zero_g = None\n",
        "      one_g = disc_1(gen_fake)\n",
        "      #fake labels\n",
        "      lab0_g = None\n",
        "      lab1_g = torch.ones(len(gen_fake)).long().to(device)\n",
        "    elif len(one_labels)==0 and len(zero_labels) > 0:\n",
        "      #discriminator output\n",
        "      out0 = disc_0(gen_fake)\n",
        "      out1 = disc_1(gen_real)\n",
        "      #discriminator labels\n",
        "      lab0 = torch.ones(len(gen_fake)).long().to(device)\n",
        "      lab1 = torch.zeros(len(gen_real)).long().to(device)\n",
        "      #output to check how well fake fools discriminator\n",
        "      zero_g = disc_0(gen_fake)\n",
        "      one_g = None\n",
        "      #fake labels\n",
        "      lab1_g = None\n",
        "      lab0_g = torch.ones(len(gen_fake)).long().to(device)\n",
        "    else:\n",
        "      #all zero samples\n",
        "      g0 = torch.cat((gen_real[zero_labels],gen_fake[one_labels]),0)\n",
        "      #all one samples\n",
        "      g1 = torch.cat((gen_real[one_labels],gen_fake[zero_labels]),0)\n",
        "      #discriminator outputs\n",
        "      out0 = disc_0(g0)\n",
        "      out1 = disc_1(g1)\n",
        "      #discriminator labels\n",
        "      lab0 = torch.cat((torch.ones(len(zero_labels)),torch.zeros(len(one_labels))),0).long().to(device)\n",
        "      lab1 = torch.cat((torch.ones(len(one_labels)),torch.zeros(len(zero_labels))),0).long().to(device)\n",
        "      #output to check how well fake fools discriminator\n",
        "      zero_g = disc_0(gen_fake[one_labels])\n",
        "      one_g = disc_1(gen_fake[zero_labels])\n",
        "      #fake labels\n",
        "      lab0_g = torch.ones(len(one_labels)).long().to(device)\n",
        "      lab1_g = torch.ones(len(zero_labels)).long().to(device)\n",
        "    #discrimminator loss\n",
        "    l0 = lf2(out0,lab0)\n",
        "    l1 = lf2(out1,lab1)\n",
        "    #loss for fooling discriminator\n",
        "    if zero_g is not None:\n",
        "      l0_g = lf2(zero_g,lab0_g)\n",
        "    else:\n",
        "      l0_g = 0\n",
        "    if one_g is not None:\n",
        "      l1_g = lf2(one_g,lab1_g)\n",
        "    else:\n",
        "      l1_g = 0\n",
        "    #reconstruction loss\n",
        "    rec_loss = loss_func(gen,oh)\n",
        "    loss = torch.mean(rec_loss) + (l0_g + l1_g)\n",
        "    losses = [l0,l1,loss]\n",
        "    #backward all gradients\n",
        "    g = 0\n",
        "    while g < 3:\n",
        "      optimizer[g].zero_grad()\n",
        "      losses[g].backward(retain_graph=True)\n",
        "      torch.nn.utils.clip_grad_norm_(models[g].parameters(),max_norm=1)\n",
        "      g += 1\n",
        "    g = 0\n",
        "    while g < 3:\n",
        "      optimizer[g].step()\n",
        "      g += 1\n",
        "    #record loss\n",
        "    mask = rec_loss != 0\n",
        "    lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "    k += 1\n",
        "  #check validation loss\n",
        "  trainloss.append(lp/len(input))\n",
        "  with torch.no_grad():\n",
        "    k = 0\n",
        "    lp = 0\n",
        "    while k < len(validation)//256:\n",
        "      inp = validation[k*256:(k+1)*256]\n",
        "      oh = inp[:,1:mlen].long()\n",
        "      class_inp = one_hot(vlabels[k*256:(k+1)*256],2).to(device)\n",
        "      le = vlengs[k*256:(k+1)*256]\n",
        "      y = net.style_layer(class_inp)\n",
        "      x = net.embedding(inp)\n",
        "      ex = torch.cat((y.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "      ex = pack_padded_sequence(ex,le,batch_first=True,enforce_sorted=False)\n",
        "      _,(henc,_) = net.enc(ex)\n",
        "      henc = henc.view((henc.size()[1],henc.size()[2]*2*net.numlayers))\n",
        "      gen = torch.zeros((henc.size()[0],net.nvocab,net.genlen)).to(device)\n",
        "      p = 0\n",
        "      while p < net.genlen:\n",
        "        ip = torch.cat((henc,y,x[:,p,:]),1)\n",
        "        kp,_ = net.dec(ip)\n",
        "        kp = net.llayer(kp)\n",
        "        gen[:,:,p] = kp\n",
        "        p += 1\n",
        "      rec_loss = loss_func(gen,oh)\n",
        "      mask = rec_loss != 0\n",
        "      lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "      k += 1\n",
        "  valloss.append(lp/len(validation))  \n",
        "  print(i,trainloss[-1],valloss[-1])\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlQ1fq58g_54"
      },
      "source": [
        "#calculate BLEU and ROUGE\n",
        "import nltk\n",
        "import rouge\n",
        "nltk.download('punkt')\n",
        "apply_avg = True\n",
        "apply_best = False\n",
        "evaluator = rouge.Rouge(metrics=['rouge-n'],\n",
        "                           max_n=4,\n",
        "                           limit_length=True,\n",
        "                           length_limit=100,\n",
        "                           length_limit_type='words',\n",
        "                           apply_avg=apply_avg,\n",
        "                           apply_best=apply_best,\n",
        "                           alpha=0.5, # Default F1_score\n",
        "                           weight_factor=1.2,\n",
        "                           stemming=True)\n",
        "def eval_inp(inp,class_inp,le):\n",
        "  y = net.style_layer(class_inp)\n",
        "  x = net.embedding(inp)\n",
        "  ex = torch.cat((y.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "  ex = pack_padded_sequence(ex,le,batch_first=True,enforce_sorted=False)\n",
        "  _,(henc,_) = net.enc(ex)\n",
        "  henc = henc.view((henc.size()[1],henc.size()[2]*2*net.numlayers))\n",
        "  gen = torch.zeros((henc.size()[0],net.nvocab,net.genlen)).to(device)\n",
        "  p = 0\n",
        "  while p < net.genlen:\n",
        "    ip = torch.cat((henc,y,x[:,p,:]),1)\n",
        "    kp,_ = net.dec(ip)\n",
        "    kp = net.llayer(kp)\n",
        "    gen[:,:,p] = kp\n",
        "    p += 1\n",
        "  return gen\n",
        "bleu_tref = []\n",
        "bleu_thyp = []\n",
        "bleu_vref = []\n",
        "bleu_vhyp = []\n",
        "rouge_tref = []\n",
        "rouge_thyp = []\n",
        "rouge_vref = []\n",
        "rouge_vhyp = []\n",
        "ke = list(vocab.keys())\n",
        "k = 0\n",
        "while k < len(input):\n",
        "  l = []\n",
        "  for j in input[k]:\n",
        "    if j.cpu().item() == 2:\n",
        "      pass\n",
        "    elif j.cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      l.append(ke[j.cpu().item()])\n",
        "  bleu_tref.append([l])\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(l):\n",
        "    if i == len(l) - 1:\n",
        "      rs += l[i]\n",
        "    else:\n",
        "      rs += l[i] + ' '\n",
        "    i += 1\n",
        "  rouge_tref.append(rs)\n",
        "  with torch.no_grad():\n",
        "    out = eval_inp(input[k:k+1],one_hot(labels[k:k+1],2).to(device),lengs[k:k+1])\n",
        "  out = out.reshape((out.size()[1],-1))\n",
        "  sents = torch.max(out,0)[1]\n",
        "  gsen = []\n",
        "  p = 0\n",
        "  while p < len(sents):\n",
        "    if sents[p].cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      gsen.append(ke[sents[p].cpu().item()])\n",
        "    p += 1\n",
        "  bleu_thyp.append(gsen)\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(gsen):\n",
        "    if i == len(gsen) - 1:\n",
        "      rs += gsen[i]\n",
        "    else:\n",
        "      rs += gsen[i] + ' '\n",
        "    i += 1\n",
        "  rouge_thyp.append(rs)\n",
        "  k += 1\n",
        "k = 0\n",
        "while k < len(validation):\n",
        "  l = []\n",
        "  for j in validation[k]:\n",
        "    if j.cpu().item() == 2:\n",
        "      pass\n",
        "    elif j.cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      l.append(ke[j.cpu().item()])\n",
        "  bleu_vref.append([l])\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(l):\n",
        "    if i == len(l) - 1:\n",
        "      rs += l[i]\n",
        "    else:\n",
        "      rs += l[i] + ' '\n",
        "    i += 1\n",
        "  rouge_vref.append(rs)\n",
        "  out = eval_inp(validation[k:k+1],one_hot(vlabels[k:k+1],2).to(device),vlengs[k:k+1])\n",
        "  out = out.reshape((out.size()[1],-1))\n",
        "  sents = torch.max(out,0)[1]\n",
        "  gsen = []\n",
        "  p = 0\n",
        "  while p < len(sents):\n",
        "    if sents[p].cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      gsen.append(ke[sents[p].cpu().item()])\n",
        "    p += 1\n",
        "  bleu_vhyp.append(gsen)\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(gsen):\n",
        "    if i == len(gsen) - 1:\n",
        "      rs += gsen[i]\n",
        "    else:\n",
        "      rs += gsen[i] + ' '\n",
        "    i += 1\n",
        "  rouge_vhyp.append(rs)\n",
        "  k += 1\n",
        "tscores = evaluator.get_scores(rouge_tref, rouge_thyp)\n",
        "vscores = evaluator.get_scores(rouge_vref, rouge_vhyp)\n",
        "print('BLEU Score Training')\n",
        "print(nltk.translate.bleu_score.corpus_bleu(bleu_tref,bleu_thyp))\n",
        "print('BLEU Score Validation')\n",
        "print(nltk.translate.bleu_score.corpus_bleu(bleu_vref,bleu_vhyp))\n",
        "print('ROUGE-1 Training')\n",
        "print(tscores['rouge-1']['f'])\n",
        "print('ROUGE-2 Training')\n",
        "print(tscores['rouge-2']['f'])\n",
        "print('ROUGE-1 Validation')\n",
        "print(vscores['rouge-1']['f'])\n",
        "print('ROUGE-2 Validation')\n",
        "print(vscores['rouge-2']['f'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnShKs-YMg-1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np \n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "device = torch.device('cuda:0')\n",
        "#Cross aligned with LSTM and Attention,style as linear layer\n",
        "class LSTM_ATN_CAE(nn.Module):\n",
        "  def __init__(self, input_length, hidden_z,num_classes, len_style, attn_length, layers,vocab_length, gen_length,temp):\n",
        "    super(LSTM_ATN_CAE,self).__init__()\n",
        "    #number of classes\n",
        "    self.numclasses = num_classes\n",
        "    #generation length\n",
        "    self.genlen = gen_length\n",
        "    #hidden generator dim\n",
        "    self.hidz = hidden_z\n",
        "    #embedding dim\n",
        "    self.inp = input_length\n",
        "    #vocab size\n",
        "    self.nvocab = vocab_length\n",
        "    #encoder\n",
        "    self.enc = nn.LSTM(input_length+len_style,hidden_z,layers,batch_first=True)\n",
        "    #expanding style information\n",
        "    self.style_layer = nn.Linear(num_classes,len_style)\n",
        "    #generator\n",
        "    self.dec = nn.LSTMCell(input_length+hidden_z+len_style,hidden_z)\n",
        "    #attention linear layer - only need one because latent and encoder hidden dim are same length\n",
        "    self.attn = nn.Linear(hidden_z,attn_length)\n",
        "    #reduce to vector\n",
        "    self.attn_reduce = nn.Linear(attn_length,1)\n",
        "    #RELU activation\n",
        "    self.relu = nn.ReLU()\n",
        "    #number of layers\n",
        "    self.numlayers = layers\n",
        "    #word emebeddings\n",
        "    self.embedding = nn.Embedding(vocab_length,input_length, padding_idx=0)\n",
        "    #expand to vocab size\n",
        "    self.llayer = nn.Linear(hidden_z,vocab_length)\n",
        "    #softmax\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    #temperature\n",
        "    self.temp = temp\n",
        "  def forward(self,x,y,les):\n",
        "    #real labels\n",
        "    oy = self.style_layer(one_hot(y,2).to(device))\n",
        "    #transferred labels\n",
        "    mody = self.style_layer(one_hot(1-y,2).to(device))\n",
        "    #get word embeddings\n",
        "    x = self.embedding(x)\n",
        "    #pass through encoder\n",
        "    ex = torch.cat((oy.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "    ex = pack_padded_sequence(ex,les,batch_first=True,enforce_sorted=False)\n",
        "    out,(z,_) = self.enc(ex)\n",
        "    out = pad_packed_sequence(out,batch_first=True,total_length=x.size()[1])[0]\n",
        "    z = z.view((z.size()[1],z.size()[2]*self.numlayers))\n",
        "    #inputs for discriminator\n",
        "    gen_fake = torch.zeros((x.size()[0],self.genlen,self.hidz)).to(device)\n",
        "    gen_real = torch.zeros((x.size()[0],self.genlen,self.hidz)).to(device)\n",
        "    #distribution over vocab for reconstruction loss\n",
        "    gen = torch.zeros((x.size()[0],self.nvocab,self.genlen)).to(device)\n",
        "    i = 0\n",
        "    #iterate over generation length\n",
        "    while i < self.genlen:\n",
        "      if i == 0:\n",
        "        #attention weights\n",
        "        attn_weights = self.softmax(self.attn_reduce(self.relu(self.attn(out) + self.attn(z.unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "        attn_weights = attn_weights.view((attn_weights.size()[0],1,attn_weights.size()[1]))\n",
        "        #apply weighting\n",
        "        attn_vec = torch.bmm(attn_weights,out)\n",
        "        attn_vec = attn_vec.view((attn_vec.size()[0],attn_vec.size()[2]))\n",
        "        #real and fake input to generator\n",
        "        inp1 = torch.cat((attn_vec,oy,x[:,i,:]),1)\n",
        "        inp2 = torch.cat((attn_vec,mody,x[:,i,:]),1)\n",
        "      else:\n",
        "        #need two attention mechanisms - one for teacher forced (real) and one for free running (fake)\n",
        "        attn_weights_real = self.softmax(self.attn_reduce(self.relu(self.attn(out) + self.attn(z[0:cut].unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "        attn_weights_real = attn_weights_real.view((attn_weights_real.size()[0],1,attn_weights_real.size()[1]))\n",
        "        attn_vec_real = torch.bmm(attn_weights_real,out)\n",
        "        attn_vec_real = attn_vec_real.view((attn_vec_real.size()[0],attn_vec_real.size()[2]))\n",
        "        attn_weights_fake = self.softmax(self.attn_reduce(self.relu(self.attn(out) + self.attn(z[cut:].unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "        attn_weights_fake = attn_weights_fake.view((attn_weights_fake.size()[0],1,attn_weights_fake.size()[1]))\n",
        "        attn_vec_fake = torch.bmm(attn_weights_fake,out)\n",
        "        attn_vec_fake = attn_vec_fake.view((attn_vec_fake.size()[0],attn_vec_fake.size()[2]))\n",
        "        #real and fake input to generator\n",
        "        inp1 = torch.cat((attn_vec_real,oy,x[:,i,:]),1)\n",
        "        inp2 = torch.cat((attn_vec_fake,mody,all_embed),1)\n",
        "      #pass through generator\n",
        "      ip = torch.cat((inp1,inp2),0)\n",
        "      z,_ = self.dec(ip)\n",
        "      #get discriminator output\n",
        "      cut = int(len(z)/2)\n",
        "      gen_real[:,i,:] = z[0:cut]\n",
        "      gen_fake[:,i,:] = z[cut:len(z)]\n",
        "      #expand to vocab size\n",
        "      kp = self.llayer(z)\n",
        "      cut = int(len(kp)/2)\n",
        "      #rescale\n",
        "      kp = (kp - torch.max(kp,dim=1)[0].unsqueeze(1).repeat(1,kp.size()[1]))\n",
        "      #store distribution\n",
        "      gen[:,:,i] = kp[0:cut]\n",
        "      #get weighted average words for fake\n",
        "      su = torch.sum(torch.exp(kp[cut:len(kp)]/self.temp),axis=1)\n",
        "      softmax = (torch.exp(kp[cut:len(kp)]/self.temp).T/(su)).T\n",
        "      ta = torch.arange(self.nvocab).to(device)\n",
        "      all_embed = self.embedding(ta)\n",
        "      all_embed = softmax@all_embed\n",
        "      i += 1\n",
        "    return gen,gen_real,gen_fake\n",
        "#discriminator\n",
        "class Disc(nn.Module):\n",
        "  def __init__(self, input_length,disc_hidden_length):\n",
        "    super(Disc,self).__init__()\n",
        "    self.disc = nn.LSTM(input_length,disc_hidden_length,batch_first=True,bidirectional=True)    \n",
        "    self.disc_linear = nn.Linear(disc_hidden_length*2,2)\n",
        "  def forward(self,disc_store):\n",
        "    _,(hid,_) = self.disc(disc_store)\n",
        "    hid = hid.reshape((hid.size()[1],hid.size()[2]*2))\n",
        "    hid = self.disc_linear(hid)\n",
        "    return hid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne4IuxsL1gUX"
      },
      "source": [
        "#CAE with LSTM with attention, style as linear layer training\n",
        "#set seeds for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "np.random.seed(100)\n",
        "torch.manual_seed(100)\n",
        "torch.cuda.manual_seed(100)\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "#choose which labels to use - two at a time\n",
        "ind = np.array(author_labels)\n",
        "a0 = np.where(ind==0)[0]\n",
        "a1 = np.where(ind==2)[0]\n",
        "ind[a0] = 0\n",
        "ind[a1] = 1\n",
        "avail_poems = np.array(r_authors_poem_line,dtype='object')[np.concatenate((a0,a1))]\n",
        "avail_ind = ind[np.concatenate((a0,a1))]\n",
        "#sequence length\n",
        "mlen = 15\n",
        "#get vocab, labels, lengths, and numbered input for network\n",
        "vocab = create_vocab_dict(avail_poems,mincount=0)\n",
        "padded,lab,lengs = vnorm(avail_poems,vocab,avail_ind,mlen)\n",
        "#divide into training and vaildaiton\n",
        "fp = np.array(lab)\n",
        "_,rc = np.unique(fp,return_counts=True)\n",
        "cut = np.array(np.round(rc*0.8),dtype=int)\n",
        "w0 = np.where(fp==0)[0]\n",
        "w1 = np.where(fp==1)[0]\n",
        "np.random.shuffle(w0)\n",
        "np.random.shuffle(w1)\n",
        "trind =  np.concatenate((w0[0:cut[0]],w1[0:cut[1]]))\n",
        "vind = np.concatenate((w0[cut[0]:len(w0)],w1[cut[1]:len(w1)]))\n",
        "train_track = np.arange(len(trind))\n",
        "valid_track = np.arange(len(vind))\n",
        "lof = np.array(lengs)\n",
        "lengs = lof[trind]\n",
        "vlengs = lof[vind]\n",
        "input = torch.tensor(padded)[trind].to(device)\n",
        "validation = torch.tensor(padded)[vind].to(device)\n",
        "labels = torch.tensor(lab)[trind].to(device)\n",
        "vlabels = torch.tensor(lab)[vind].to(device)\n",
        "#weighting to ignore gradient over padding and unk tokens\n",
        "weights = torch.ones(len(vocab.keys())).to(device)\n",
        "weights[3] = 0\n",
        "weights[0] = 0\n",
        "#initialize network, discriminators, loss and optimizers\n",
        "net = LSTM_ATN_CAE(300,300,2,50,50,1,len(vocab.keys()),mlen-1,10)\n",
        "disc_0 = Disc(300,100)\n",
        "disc_1 = Disc(300,100)\n",
        "loss_func = nn.CrossEntropyLoss(weight=weights,reduction='none')\n",
        "lf2 = nn.CrossEntropyLoss(reduction='mean')\n",
        "net = net.to(device)\n",
        "disc_0 = disc_0.to(device)\n",
        "disc_1 = disc_1.to(device)\n",
        "opt1 = torch.optim.Adam(net.parameters(),lr=0.0001)\n",
        "opt2 = torch.optim.Adam(disc_0.parameters(),lr=0.0001)\n",
        "opt3 = torch.optim.Adam(disc_1.parameters(),lr=0.0001)\n",
        "optimizer = [opt3,opt2,opt1]\n",
        "models = [disc_0,disc_1,net]\n",
        "trainloss = []\n",
        "traindisc = []\n",
        "valloss = []\n",
        "td = []\n",
        "batch_size=256\n",
        "i = 0\n",
        "while i < 500:\n",
        "  #sample random minibatch\n",
        "  np.random.shuffle(train_track)\n",
        "  k = 0\n",
        "  lp = 0\n",
        "  klp = 0\n",
        "  while k < len(trind)//batch_size + 1:\n",
        "    #inputs for network\n",
        "    inp = input[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    les = lengs[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    oh = inp[:,1:mlen].long().to(device)\n",
        "    curlab = labels[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    #pass through network\n",
        "    gen,gen_real,gen_fake = net(inp,curlab,les)\n",
        "    #find where labels are 0 and 1\n",
        "    zero_labels = torch.where(curlab==0)[0]\n",
        "    one_labels = torch.where(curlab==1)[0]\n",
        "    #three possibilities - all 0, all 1, both\n",
        "    if len(zero_labels)==0 and len(one_labels) > 0:\n",
        "      #discriminator output\n",
        "      out0 = disc_0(gen_real)\n",
        "      out1 = disc_1(gen_fake)\n",
        "      #discriminator labels\n",
        "      lab0 = torch.ones(len(gen_real)).long().to(device)\n",
        "      lab1 = torch.zeros(len(gen_fake)).long().to(device)\n",
        "      #output to check if discriminator is fooled\n",
        "      zero_g = None\n",
        "      one_g = disc_1(gen_fake)\n",
        "      #fake labels\n",
        "      lab0_g = None\n",
        "      lab1_g = torch.ones(len(gen_fake)).long().to(device)\n",
        "    elif len(one_labels)==0 and len(zero_labels) > 0:\n",
        "      #discriminator output\n",
        "      out0 = disc_0(gen_fake)\n",
        "      out1 = disc_1(gen_real)\n",
        "      #discriminator labels\n",
        "      lab0 = torch.ones(len(gen_fake)).long().to(device)\n",
        "      lab1 = torch.zeros(len(gen_real)).long().to(device)\n",
        "      #output to check if discriminator is fooled\n",
        "      zero_g = disc_0(gen_fake)\n",
        "      one_g = None\n",
        "      #fake labels\n",
        "      lab1_g = None\n",
        "      lab0_g = torch.ones(len(gen_fake)).long().to(device)\n",
        "    else:\n",
        "      #put all 0 and all 1 samples together\n",
        "      g0 = torch.cat((gen_real[zero_labels],gen_fake[one_labels]),0)\n",
        "      g1 = torch.cat((gen_real[one_labels],gen_fake[zero_labels]),0)\n",
        "      #discriminator output\n",
        "      out0 = disc_0(g0)\n",
        "      out1 = disc_1(g1)\n",
        "      #discriminator labels\n",
        "      lab0 = torch.cat((torch.ones(len(zero_labels)),torch.zeros(len(one_labels))),0).long().to(device)\n",
        "      lab1 = torch.cat((torch.ones(len(one_labels)),torch.zeros(len(zero_labels))),0).long().to(device)\n",
        "      #output to check if discriminator is fooled\n",
        "      zero_g = disc_0(gen_fake[one_labels])\n",
        "      one_g = disc_1(gen_fake[zero_labels])\n",
        "      #fake labels\n",
        "      lab0_g = torch.ones(len(one_labels)).long().to(device)\n",
        "      lab1_g = torch.ones(len(zero_labels)).long().to(device)\n",
        "    #discriminator loss\n",
        "    l0 = lf2(out0,lab0)\n",
        "    l1 = lf2(out1,lab1)\n",
        "    #loss for fooling discriminator\n",
        "    if zero_g is not None:\n",
        "      l0_g = lf2(zero_g,lab0_g)\n",
        "    else:\n",
        "      l0_g = 0\n",
        "    if one_g is not None:\n",
        "      l1_g = lf2(one_g,lab1_g)\n",
        "    else:\n",
        "      l1_g = 0\n",
        "    #reconstruction loss\n",
        "    rec_loss = loss_func(gen,oh)\n",
        "    loss = torch.mean(rec_loss) + (l0_g + l1_g)\n",
        "    losses = [l0,l1,loss]\n",
        "    #backward gradient\n",
        "    g = 0\n",
        "    while g < 3:\n",
        "      optimizer[g].zero_grad()\n",
        "      losses[g].backward(retain_graph=True)\n",
        "      torch.nn.utils.clip_grad_norm_(models[g].parameters(),max_norm=1)\n",
        "      g += 1\n",
        "    g = 0\n",
        "    while g < 3:\n",
        "      optimizer[g].step()\n",
        "      g += 1\n",
        "    #record loss\n",
        "    mask = rec_loss != 0\n",
        "    lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "    k += 1\n",
        "  trainloss.append(lp/len(input))\n",
        "  #check validation error\n",
        "  with torch.no_grad():\n",
        "    k = 0\n",
        "    lp = 0\n",
        "    while k < len(validation)//256:\n",
        "      inp = validation[k*256:(k+1)*256]\n",
        "      oh = inp[:,1:mlen].long()\n",
        "      class_inp = one_hot(vlabels[k*256:(k+1)*256],2).to(device)\n",
        "      le = vlengs[k*256:(k+1)*256]\n",
        "      y = net.style_layer(class_inp)\n",
        "      x = net.embedding(inp)\n",
        "      ex = torch.cat((y.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "      ex = pack_padded_sequence(ex,le,batch_first=True,enforce_sorted=False)\n",
        "      out,(z,_) = net.enc(ex)\n",
        "      out = pad_packed_sequence(out,batch_first=True,total_length=x.size()[1])[0]\n",
        "      z = z.view((z.size()[1],z.size()[2]*net.numlayers))\n",
        "      gen = torch.zeros((x.size()[0],net.nvocab,net.genlen)).to(device)\n",
        "      p = 0\n",
        "      while p < net.genlen:\n",
        "        attn_weights = net.softmax(net.attn_reduce(net.relu(net.attn(out) + net.attn(z.unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "        attn_weights = attn_weights.view((attn_weights.size()[0],1,attn_weights.size()[1]))\n",
        "        attn_vec = torch.bmm(attn_weights,out)\n",
        "        attn_vec = attn_vec.view((attn_vec.size()[0],attn_vec.size()[2]))\n",
        "        ip = torch.cat((attn_vec,y,x[:,p,:]),1)\n",
        "        z,_ = net.dec(ip)\n",
        "        kp = net.llayer(z)\n",
        "        gen[:,:,p] = kp\n",
        "        p += 1\n",
        "      rec_loss = loss_func(gen,oh)\n",
        "      mask = rec_loss != 0\n",
        "      lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "      k += 1\n",
        "  valloss.append(lp/len(validation))  \n",
        "  print(i,trainloss[-1],valloss[-1])\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt_lEwi4hyHQ"
      },
      "source": [
        "#calculate BLEU and ROUGE for CAE with attention\n",
        "import nltk\n",
        "import rouge\n",
        "nltk.download('punkt')\n",
        "apply_avg = True\n",
        "apply_best = False\n",
        "evaluator = rouge.Rouge(metrics=['rouge-n'],\n",
        "                           max_n=4,\n",
        "                           limit_length=True,\n",
        "                           length_limit=100,\n",
        "                           length_limit_type='words',\n",
        "                           apply_avg=apply_avg,\n",
        "                           apply_best=apply_best,\n",
        "                           alpha=0.5, # Default F1_score\n",
        "                           weight_factor=1.2,\n",
        "                           stemming=True)\n",
        "def eval_inp(inp,class_inp,le):\n",
        "  with torch.no_grad():\n",
        "    y = net.style_layer(class_inp)\n",
        "    x = net.embedding(inp)\n",
        "    ex = torch.cat((y.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "    ex = pack_padded_sequence(ex,le,batch_first=True,enforce_sorted=False)\n",
        "    out,(hz,_) = net.enc(ex)\n",
        "    out = pad_packed_sequence(out,batch_first=True,total_length=x.size()[1])[0]\n",
        "    z = hz.view((hz.size()[1],hz.size()[2]*net.numlayers))\n",
        "    gen = torch.zeros((hz.size()[0],net.nvocab,net.genlen)).to(device)\n",
        "    p = 0\n",
        "    while p < net.genlen:\n",
        "      attn_weights = net.softmax(net.attn_reduce(net.relu(net.attn(out) + net.attn(z.unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "      attn_weights = attn_weights.view((attn_weights.size()[0],1,attn_weights.size()[1]))\n",
        "      attn_vec = torch.bmm(attn_weights,out)\n",
        "      attn_vec = attn_vec.view((attn_vec.size()[0],attn_vec.size()[2]))\n",
        "      ip = torch.cat((attn_vec,y,x[:,p,:]),1)\n",
        "      z,_ = net.dec(ip)\n",
        "      hid = net.llayer(z)\n",
        "      gen[:,:,p] = hid\n",
        "      p += 1\n",
        "  return gen\n",
        "bleu_tref = []\n",
        "bleu_thyp = []\n",
        "bleu_vref = []\n",
        "bleu_vhyp = []\n",
        "rouge_tref = []\n",
        "rouge_thyp = []\n",
        "rouge_vref = []\n",
        "rouge_vhyp = []\n",
        "ke = list(vocab.keys())\n",
        "k = 0\n",
        "while k < len(input):\n",
        "  l = []\n",
        "  for j in input[k]:\n",
        "    if j.cpu().item() == 2:\n",
        "      pass\n",
        "    elif j.cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      l.append(ke[j.cpu().item()])\n",
        "  bleu_tref.append([l])\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(l):\n",
        "    if i == len(l) - 1:\n",
        "      rs += l[i]\n",
        "    else:\n",
        "      rs += l[i] + ' '\n",
        "    i += 1\n",
        "  rouge_tref.append(rs)\n",
        "  out = eval_inp(input[k:k+1],one_hot(labels[k:k+1],2).to(device),lengs[k:k+1])\n",
        "  out = out.reshape((out.size()[1],-1))\n",
        "  sents = torch.max(out,0)[1]\n",
        "  gsen = []\n",
        "  p = 0\n",
        "  while p < len(sents):\n",
        "    if sents[p].cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      gsen.append(ke[sents[p].cpu().item()])\n",
        "    p += 1\n",
        "  bleu_thyp.append(gsen)\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(gsen):\n",
        "    if i == len(gsen) - 1:\n",
        "      rs += gsen[i]\n",
        "    else:\n",
        "      rs += gsen[i] + ' '\n",
        "    i += 1\n",
        "  rouge_thyp.append(rs)\n",
        "  k += 1\n",
        "k = 0\n",
        "while k < len(validation):\n",
        "  l = []\n",
        "  for j in validation[k]:\n",
        "    if j.cpu().item() == 2:\n",
        "      pass\n",
        "    elif j.cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      l.append(ke[j.cpu().item()])\n",
        "  bleu_vref.append([l])\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(l):\n",
        "    if i == len(l) - 1:\n",
        "      rs += l[i]\n",
        "    else:\n",
        "      rs += l[i] + ' '\n",
        "    i += 1\n",
        "  rouge_vref.append(rs)\n",
        "  out = eval_inp(validation[k:k+1],one_hot(vlabels[k:k+1],2).to(device),vlengs[k:k+1])\n",
        "  out = out.reshape((out.size()[1],-1))\n",
        "  sents = torch.max(out,0)[1]\n",
        "  gsen = []\n",
        "  p = 0\n",
        "  while p < len(sents):\n",
        "    if sents[p].cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      gsen.append(ke[sents[p].cpu().item()])\n",
        "    p += 1\n",
        "  bleu_vhyp.append(gsen)\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(gsen):\n",
        "    if i == len(gsen) - 1:\n",
        "      rs += gsen[i]\n",
        "    else:\n",
        "      rs += gsen[i] + ' '\n",
        "    i += 1\n",
        "  rouge_vhyp.append(rs)\n",
        "  k += 1\n",
        "tscores = evaluator.get_scores(rouge_tref, rouge_thyp)\n",
        "vscores = evaluator.get_scores(rouge_vref, rouge_vhyp)\n",
        "print('BLEU Score Training')\n",
        "print(nltk.translate.bleu_score.corpus_bleu(bleu_tref,bleu_thyp))\n",
        "print('BLEU Score Validation')\n",
        "print(nltk.translate.bleu_score.corpus_bleu(bleu_vref,bleu_vhyp))\n",
        "print('ROUGE-1 Training')\n",
        "print(tscores['rouge-1']['f'])\n",
        "print('ROUGE-2 Training')\n",
        "print(tscores['rouge-2']['f'])\n",
        "print('ROUGE-1 Validation')\n",
        "print(vscores['rouge-1']['f'])\n",
        "print('ROUGE-2 Validation')\n",
        "print(vscores['rouge-2']['f'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pczLH_1UO9o3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np \n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch.nn.functional import softmax\n",
        "device = torch.device('cuda:0')\n",
        "#Cross aligned with bidirectional LSTM and attention,style as linear layer\n",
        "class LSTM_ATN_CAE_BD(nn.Module):\n",
        "  def __init__(self, input_length, hidden_z,num_classes, len_style, attn_length, layers,vocab_length, gen_length,temp):\n",
        "    super(LSTM_ATN_CAE_BD,self).__init__()\n",
        "    #number of classes\n",
        "    self.numclasses = num_classes\n",
        "    #generation length\n",
        "    self.genlen = gen_length\n",
        "    #embedding dim\n",
        "    self.inp = input_length\n",
        "    #hidden generator dim\n",
        "    self.hidz = 2*hidden_z\n",
        "    #vocab length\n",
        "    self.nvocab = vocab_length\n",
        "    #encoder\n",
        "    self.enc = nn.LSTM(input_length+len_style,hidden_z,layers,batch_first=True,bidirectional=True)\n",
        "    #style information layer\n",
        "    self.style_layer = nn.Linear(num_classes,len_style)\n",
        "    #decoder\n",
        "    self.dec = nn.LSTMCell(input_length+2*hidden_z+len_style,2*hidden_z)\n",
        "    #attention layer - only one since hidden states same dim\n",
        "    self.attn = nn.Linear(2*hidden_z,attn_length)\n",
        "    #reduce attention to vector\n",
        "    self.attn_reduce = nn.Linear(attn_length,1)\n",
        "    #ReLU activation\n",
        "    self.relu = nn.ReLU()\n",
        "    #word embeddings\n",
        "    self.embedding = nn.Embedding(vocab_length,input_length, padding_idx=0)\n",
        "    #expand to vocab length\n",
        "    self.llayer = nn.Linear(2*hidden_z,vocab_length)\n",
        "    #number of layers\n",
        "    self.numlayers = layers\n",
        "    #softmax\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    #temperature\n",
        "    self.temp = temp\n",
        "  def forward(self,x,y,les):\n",
        "    #real labels\n",
        "    oy = self.style_layer(one_hot(y,2).to(device))\n",
        "    #transferred labels\n",
        "    mody = self.style_layer(one_hot(1-y,2).to(device))\n",
        "    #get word embeddings\n",
        "    x = self.embedding(x)\n",
        "    #pass through encoder\n",
        "    ex = torch.cat((oy.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "    ex = pack_padded_sequence(ex,les,batch_first=True,enforce_sorted=False)\n",
        "    out,(z,_) = self.enc(ex)\n",
        "    out = pad_packed_sequence(out,batch_first=True,total_length=x.size()[1])[0]\n",
        "    z = z.view((z.size()[1],z.size()[2]*2*self.numlayers))\n",
        "    #transferred samples\n",
        "    gen_fake = torch.zeros((x.size()[0],self.genlen,self.hidz)).to(device)\n",
        "    #real samples\n",
        "    gen_real = torch.zeros((x.size()[0],self.genlen,self.hidz)).to(device)\n",
        "    #distribution over vocab\n",
        "    gen = torch.zeros((x.size()[0],self.nvocab,self.genlen)).to(device)\n",
        "    i = 0\n",
        "    while i < self.genlen:\n",
        "      if i == 0:\n",
        "        #at first step we have same initial - create attention weights\n",
        "        attn_weights = self.softmax(self.attn_reduce(self.relu(self.attn(out) + self.attn(z.unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "        attn_weights = attn_weights.view((attn_weights.size()[0],1,attn_weights.size()[1]))\n",
        "        #apply weighting\n",
        "        attn_vec = torch.bmm(attn_weights,out)\n",
        "        attn_vec = attn_vec.view((attn_vec.size()[0],attn_vec.size()[2]))\n",
        "        #create real and transferred input\n",
        "        inp1 = torch.cat((attn_vec,oy,x[:,i,:]),1)\n",
        "        inp2 = torch.cat((attn_vec,mody,x[:,0,:]),1)\n",
        "      else:\n",
        "        #attention for real samples\n",
        "        attn_weights_real = self.softmax(self.attn_reduce(self.relu(self.attn(out) + self.attn(z[0:cut].unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "        attn_weights_real = attn_weights_real.view((attn_weights_real.size()[0],1,attn_weights_real.size()[1]))\n",
        "        attn_vec_real = torch.bmm(attn_weights_real,out)\n",
        "        attn_vec_real = attn_vec_real.view((attn_vec_real.size()[0],attn_vec_real.size()[2]))\n",
        "        #attention for transferred samples\n",
        "        attn_weights_fake = self.softmax(self.attn_reduce(self.relu(self.attn(out) + self.attn(z[cut:].unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "        attn_weights_fake = attn_weights_fake.view((attn_weights_fake.size()[0],1,attn_weights_fake.size()[1]))\n",
        "        attn_vec_fake = torch.bmm(attn_weights_fake,out)\n",
        "        attn_vec_fake = attn_vec_fake.view((attn_vec_fake.size()[0],attn_vec_fake.size()[2]))\n",
        "        #create real and transferred output\n",
        "        inp1 = torch.cat((attn_vec_real,oy,x[:,i,:]),1)\n",
        "        inp2 = torch.cat((attn_vec_fake,mody,all_embed),1)\n",
        "      #pass through decoder\n",
        "      ip = torch.cat((inp1,inp2),0)\n",
        "      z,_ = self.dec(ip)\n",
        "      #get discriminator output\n",
        "      cut = int(len(z)/2)\n",
        "      gen_real[:,i,:] = z[0:cut]\n",
        "      gen_fake[:,i,:] = z[cut:len(z)]\n",
        "      #expand to vocab size\n",
        "      kp = self.llayer(z)\n",
        "      #rescale\n",
        "      kp = (kp - torch.max(kp,dim=1)[0].unsqueeze(1).repeat(1,kp.size()[1]))\n",
        "      #store distribution\n",
        "      gen[:,:,i] = kp[0:cut]\n",
        "      #get weighted average words for fake\n",
        "      su = torch.sum(torch.exp(kp[cut:len(kp)]/self.temp),axis=1)\n",
        "      softmax = (torch.exp(kp[cut:len(kp)]/self.temp).T/(su)).T\n",
        "      ta = torch.arange(self.nvocab).to(device)\n",
        "      all_embed = self.embedding(ta)\n",
        "      all_embed = softmax@all_embed\n",
        "      i += 1\n",
        "    return gen,gen_real,gen_fake\n",
        "#discriminator\n",
        "class Disc(nn.Module):\n",
        "  def __init__(self, input_length,disc_hidden_length):\n",
        "    super(Disc,self).__init__()\n",
        "    self.disc = nn.LSTM(input_length,disc_hidden_length,batch_first=True,bidirectional=True)    \n",
        "    self.disc_linear = nn.Linear(disc_hidden_length*2,2)\n",
        "  def forward(self,disc_store):\n",
        "    _,(hid,_) = self.disc(disc_store)\n",
        "    hid = hid.reshape((hid.size()[1],hid.size()[2]*2))\n",
        "    hid = self.disc_linear(hid)\n",
        "    return hid\n",
        "    return gen_store,disc_store\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE7bUcMpO99c"
      },
      "source": [
        "#CAE with BD LSTM and attention training\n",
        "#set seeds for deterministic output\n",
        "torch.backends.cudnn.deterministic = True\n",
        "np.random.seed(100)\n",
        "torch.manual_seed(100)\n",
        "torch.cuda.manual_seed(100)\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "ind = np.array(author_labels)\n",
        "#choose labels we want to use - two at a time\n",
        "a0 = np.where(ind==2)[0]\n",
        "a1 = np.where(ind==3)[0]\n",
        "ind[a0] = 0\n",
        "ind[a1] = 1\n",
        "avail_poems = np.array(r_authors_poem_line,dtype='object')[np.concatenate((a0,a1))]\n",
        "avail_ind = ind[np.concatenate((a0,a1))]\n",
        "#Sequence length\n",
        "mlen = 15\n",
        "#Get vocab, labels, lengths, and numbered input for network\n",
        "vocab = create_vocab_dict(avail_poems,mincount=0)\n",
        "padded,lab,lengs = vnorm(avail_poems,vocab,avail_ind,mlen)\n",
        "#divide into training and validation\n",
        "fp = np.array(lab)\n",
        "_,rc = np.unique(fp,return_counts=True)\n",
        "cut = np.array(np.round(rc*0.8),dtype=int)\n",
        "w0 = np.where(fp==0)[0]\n",
        "w1 = np.where(fp==1)[0]\n",
        "np.random.shuffle(w0)\n",
        "np.random.shuffle(w1)\n",
        "trind =  np.concatenate((w0[0:cut[0]],w1[0:cut[1]]))\n",
        "vind = np.concatenate((w0[cut[0]:len(w0)],w1[cut[1]:len(w1)]))\n",
        "train_track = np.arange(len(trind))\n",
        "valid_track = np.arange(len(vind))\n",
        "lof = np.array(lengs)\n",
        "lengs = lof[trind]\n",
        "vlengs = lof[vind]\n",
        "input = torch.tensor(padded)[trind].to(device)\n",
        "validation = torch.tensor(padded)[vind].to(device)\n",
        "labels = torch.tensor(lab)[trind].to(device)\n",
        "vlabels = torch.tensor(lab)[vind].to(device)\n",
        "#Weighting to ignore gradient over padding and unk tokens\n",
        "weights = torch.ones(len(vocab.keys())).to(device)\n",
        "weights[3] = 0\n",
        "weights[0] = 0\n",
        "#initialize network,discriminators, loss, and optimizers\n",
        "net = LSTM_ATN_CAE_BD(300,300,2,50,50,1,len(vocab.keys()),mlen-1,10)\n",
        "disc_0 = Disc(600,100)\n",
        "disc_1 = Disc(600,100)\n",
        "loss_func = nn.CrossEntropyLoss(weight=weights,reduction='none')\n",
        "lf2 = nn.CrossEntropyLoss(reduction='mean')\n",
        "net = net.to(device)\n",
        "disc_0 = disc_0.to(device)\n",
        "disc_1 = disc_1.to(device)\n",
        "coef = np.concatenate((np.zeros(40),np.linspace(0,1,30),np.ones(940)))\n",
        "opt1 = torch.optim.Adam(net.parameters(),lr=0.0001)\n",
        "opt2 = torch.optim.Adam(disc_0.parameters(),lr=0.0001)\n",
        "opt3 = torch.optim.Adam(disc_1.parameters(),lr=0.0001)\n",
        "optimizer = [opt3,opt2,opt1]\n",
        "models = [disc_0,disc_1,net]\n",
        "trainloss = []\n",
        "traindisc = []\n",
        "valloss = []\n",
        "td = []\n",
        "batch_size=256\n",
        "i = 0\n",
        "while i < 76:\n",
        "  #sample random minibatch\n",
        "  np.random.shuffle(train_track)\n",
        "  k = 0\n",
        "  lp = 0\n",
        "  klp = 0\n",
        "  while k < len(trind)//batch_size + 1:\n",
        "    #get inputs\n",
        "    inp = input[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    les = lengs[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    oh = inp[:,1:mlen].long().to(device)\n",
        "    curlab = labels[train_track[k*batch_size:(k+1)*batch_size]]\n",
        "    #pass through network\n",
        "    gen,gen_real,gen_fake = net(inp,curlab,les)\n",
        "    #get 0 and 1 labels indices\n",
        "    zero_labels = torch.where(curlab==0)[0]\n",
        "    one_labels = torch.where(curlab==1)[0]\n",
        "    if len(zero_labels)==0 and len(one_labels) > 0:\n",
        "      #discirminator output\n",
        "      out0 = disc_0(gen_real)\n",
        "      out1 = disc_1(gen_fake)\n",
        "      #discriminator output\n",
        "      lab0 = torch.ones(len(gen_real)).long().to(device)\n",
        "      lab1 = torch.zeros(len(gen_fake)).long().to(device)\n",
        "      #output to see if fake fools discriminator\n",
        "      zero_g = None\n",
        "      one_g = disc_1(gen_fake)\n",
        "      #fake labels\n",
        "      lab0_g = None\n",
        "      lab1_g = torch.ones(len(gen_fake)).long().to(device)\n",
        "    elif len(one_labels)==0 and len(zero_labels) > 0:\n",
        "      #discriminator output\n",
        "      out0 = disc_0(gen_fake)\n",
        "      out1 = disc_1(gen_real)\n",
        "      #discriminator labels\n",
        "      lab0 = torch.ones(len(gen_fake)).long().to(device)\n",
        "      lab1 = torch.zeros(len(gen_real)).long().to(device)\n",
        "      #output to see if fake fools discriminator\n",
        "      zero_g = disc_0(gen_fake)\n",
        "      one_g = None\n",
        "      #fake labels\n",
        "      lab1_g = None\n",
        "      lab0_g = torch.ones(len(gen_fake)).long().to(device)\n",
        "    else:\n",
        "      #put 0 and 1 together\n",
        "      g0 = torch.cat((gen_real[zero_labels],gen_fake[one_labels]),0)\n",
        "      g1 = torch.cat((gen_real[one_labels],gen_fake[zero_labels]),0)\n",
        "      #discriminator output\n",
        "      out0 = disc_0(g0)\n",
        "      out1 = disc_1(g1)\n",
        "      #discriminator labels\n",
        "      lab0 = torch.cat((torch.ones(len(zero_labels)),torch.zeros(len(one_labels))),0).long().to(device)\n",
        "      lab1 = torch.cat((torch.ones(len(one_labels)),torch.zeros(len(zero_labels))),0).long().to(device)\n",
        "      #output to see if fake fools discriminator\n",
        "      zero_g = disc_0(gen_fake[one_labels])\n",
        "      one_g = disc_1(gen_fake[zero_labels])\n",
        "      #fake labels\n",
        "      lab0_g = torch.ones(len(one_labels)).long().to(device)\n",
        "      lab1_g = torch.ones(len(zero_labels)).long().to(device)\n",
        "    #discriminator loss\n",
        "    l0 = lf2(out0,lab0)\n",
        "    l1 = lf2(out1,lab1)\n",
        "    #loss on fooling discriminator\n",
        "    if zero_g is not None:\n",
        "      l0_g = lf2(zero_g,lab0_g)\n",
        "    else:\n",
        "      l0_g = 0\n",
        "    if one_g is not None:\n",
        "      l1_g = lf2(one_g,lab1_g)\n",
        "    else:\n",
        "      l1_g = 0\n",
        "    #reconstruction loss\n",
        "    rec_loss = loss_func(gen,oh)\n",
        "    loss = torch.mean(rec_loss) + (l0_g + l1_g)\n",
        "    losses = [l0,l1,loss]\n",
        "    #backward gradients\n",
        "    g = 0\n",
        "    while g < 3:\n",
        "      optimizer[g].zero_grad()\n",
        "      losses[g].backward(retain_graph=True)\n",
        "      torch.nn.utils.clip_grad_norm_(models[g].parameters(),max_norm=1)\n",
        "      g += 1\n",
        "    g = 0\n",
        "    while g < 3:\n",
        "      optimizer[g].step()\n",
        "      g += 1\n",
        "    #record loss\n",
        "    mask = rec_loss != 0\n",
        "    lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "    k += 1\n",
        "  trainloss.append(lp/len(input))\n",
        "  #check validation error\n",
        "  with torch.no_grad():\n",
        "    k = 0\n",
        "    lp = 0\n",
        "    while k < len(validation)//256:\n",
        "      inp = validation[k*256:(k+1)*256]\n",
        "      oh = inp[:,1:mlen].long()\n",
        "      class_inp = one_hot(vlabels[k*256:(k+1)*256],2).to(device)\n",
        "      le = vlengs[k*256:(k+1)*256]\n",
        "      y = net.style_layer(class_inp)\n",
        "      x = net.embedding(inp)\n",
        "      ex = torch.cat((y.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "      ex = pack_padded_sequence(ex,le,batch_first=True,enforce_sorted=False)\n",
        "      out,(z,_) = net.enc(ex)\n",
        "      out = pad_packed_sequence(out,batch_first=True,total_length=x.size()[1])[0]\n",
        "      z = z.view((z.size()[1],z.size()[2]*2*net.numlayers))\n",
        "      gen = torch.zeros((x.size()[0],net.nvocab,net.genlen)).to(device)\n",
        "      p = 0\n",
        "      while p < net.genlen:\n",
        "        attn_weights = net.softmax(net.attn_reduce(net.relu(net.attn(out) + net.attn(z.unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "        attn_weights = attn_weights.view((attn_weights.size()[0],1,attn_weights.size()[1]))\n",
        "        attn_vec = torch.bmm(attn_weights,out)\n",
        "        attn_vec = attn_vec.view((attn_vec.size()[0],attn_vec.size()[2]))\n",
        "        ip = torch.cat((attn_vec,y,x[:,p,:]),1)\n",
        "        z,_ = net.dec(ip)\n",
        "        kp = net.llayer(z)\n",
        "        z = z[0:1]\n",
        "        gen[:,:,p] = kp\n",
        "        p += 1\n",
        "      rec_loss = loss_func(gen,oh)\n",
        "      mask = rec_loss != 0\n",
        "      lp += torch.sum(torch.sum(mask*rec_loss,1)/torch.sum(mask,1)).item()\n",
        "      k += 1\n",
        "  valloss.append(lp/len(validation))  \n",
        "  print(i,trainloss[-1],valloss[-1])\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bqz0Ek5iTL6"
      },
      "source": [
        "#get BLEU and ROUGE\n",
        "import nltk\n",
        "import rouge\n",
        "nltk.download('punkt')\n",
        "apply_avg = True\n",
        "apply_best = False\n",
        "evaluator = rouge.Rouge(metrics=['rouge-n'],\n",
        "                           max_n=4,\n",
        "                           limit_length=True,\n",
        "                           length_limit=100,\n",
        "                           length_limit_type='words',\n",
        "                           apply_avg=apply_avg,\n",
        "                           apply_best=apply_best,\n",
        "                           alpha=0.5, # Default F1_score\n",
        "                           weight_factor=1.2,\n",
        "                           stemming=True)\n",
        "def eval_inp(inp,class_inp,le):\n",
        "  with torch.no_grad():\n",
        "    y = net.style_layer(class_inp)\n",
        "    x = net.embedding(inp)\n",
        "    ex = torch.cat((y.unsqueeze(1).repeat(1,x.size()[1],1),x),2)\n",
        "    ex = pack_padded_sequence(ex,le,batch_first=True,enforce_sorted=False)\n",
        "    out,(z,_) = net.enc(ex)\n",
        "    out = pad_packed_sequence(out,batch_first=True,total_length=x.size()[1])[0]\n",
        "    z = z.view((z.size()[1],z.size()[2]*2*net.numlayers))\n",
        "    gen = torch.zeros((x.size()[0],net.nvocab,net.genlen)).to(device)\n",
        "    p = 0\n",
        "    while p < net.genlen:\n",
        "      attn_weights = net.softmax(net.attn_reduce(net.relu(net.attn(out) + net.attn(z.unsqueeze(1).repeat(1,out.size()[1],1)))))\n",
        "      attn_weights = attn_weights.view((attn_weights.size()[0],1,attn_weights.size()[1]))\n",
        "      attn_vec = torch.bmm(attn_weights,out)\n",
        "      attn_vec = attn_vec.view((attn_vec.size()[0],attn_vec.size()[2]))\n",
        "      ip = torch.cat((attn_vec,y,x[:,p,:]),1)\n",
        "      z,_ = net.dec(ip)\n",
        "      kp = net.llayer(z)\n",
        "      gen[:,:,p] = kp\n",
        "      p += 1\n",
        "  return gen\n",
        "bleu_tref = []\n",
        "bleu_thyp = []\n",
        "bleu_vref = []\n",
        "bleu_vhyp = []\n",
        "rouge_tref = []\n",
        "rouge_thyp = []\n",
        "rouge_vref = []\n",
        "rouge_vhyp = []\n",
        "ke = list(vocab.keys())\n",
        "k = 0\n",
        "while k < len(input):\n",
        "  l = []\n",
        "  for j in input[k]:\n",
        "    if j.cpu().item() == 2:\n",
        "      pass\n",
        "    elif j.cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      l.append(ke[j.cpu().item()])\n",
        "  bleu_tref.append([l])\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(l):\n",
        "    if i == len(l) - 1:\n",
        "      rs += l[i]\n",
        "    else:\n",
        "      rs += l[i] + ' '\n",
        "    i += 1\n",
        "  rouge_tref.append(rs)\n",
        "  out = eval_inp(input[k:k+1],one_hot(labels[k:k+1],2).to(device),lengs[k:k+1])\n",
        "  out = out.reshape((out.size()[1],-1))\n",
        "  sents = torch.max(out,0)[1]\n",
        "  gsen = []\n",
        "  p = 0\n",
        "  while p < len(sents):\n",
        "    if sents[p].cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      gsen.append(ke[sents[p].cpu().item()])\n",
        "    p += 1\n",
        "  bleu_thyp.append(gsen)\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(gsen):\n",
        "    if i == len(gsen) - 1:\n",
        "      rs += gsen[i]\n",
        "    else:\n",
        "      rs += gsen[i] + ' '\n",
        "    i += 1\n",
        "  rouge_thyp.append(rs)\n",
        "  k += 1\n",
        "k = 0\n",
        "while k < len(validation):\n",
        "  l = []\n",
        "  for j in validation[k]:\n",
        "    if j.cpu().item() == 2:\n",
        "      pass\n",
        "    elif j.cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      l.append(ke[j.cpu().item()])\n",
        "  bleu_vref.append([l])\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(l):\n",
        "    if i == len(l) - 1:\n",
        "      rs += l[i]\n",
        "    else:\n",
        "      rs += l[i] + ' '\n",
        "    i += 1\n",
        "  rouge_vref.append(rs)\n",
        "  out = eval_inp(validation[k:k+1],one_hot(vlabels[k:k+1],2).to(device),vlengs[k:k+1])\n",
        "  out = out.reshape((out.size()[1],-1))\n",
        "  sents = torch.max(out,0)[1]\n",
        "  gsen = []\n",
        "  p = 0\n",
        "  while p < len(sents):\n",
        "    if sents[p].cpu().item() == 1:\n",
        "      break\n",
        "    else:\n",
        "      gsen.append(ke[sents[p].cpu().item()])\n",
        "    p += 1\n",
        "  bleu_vhyp.append(gsen)\n",
        "  i = 0\n",
        "  rs = \"\"\n",
        "  while i < len(gsen):\n",
        "    if i == len(gsen) - 1:\n",
        "      rs += gsen[i]\n",
        "    else:\n",
        "      rs += gsen[i] + ' '\n",
        "    i += 1\n",
        "  rouge_vhyp.append(rs)\n",
        "  k += 1\n",
        "tscores = evaluator.get_scores(rouge_tref, rouge_thyp)\n",
        "vscores = evaluator.get_scores(rouge_vref, rouge_vhyp)\n",
        "print('BLEU Score Training')\n",
        "print(nltk.translate.bleu_score.corpus_bleu(bleu_tref,bleu_thyp))\n",
        "print('BLEU Score Validation')\n",
        "print(nltk.translate.bleu_score.corpus_bleu(bleu_vref,bleu_vhyp))\n",
        "print('ROUGE-1 Training')\n",
        "print(tscores['rouge-1']['f'])\n",
        "print('ROUGE-2 Training')\n",
        "print(tscores['rouge-2']['f'])\n",
        "print('ROUGE-1 Validation')\n",
        "print(vscores['rouge-1']['f'])\n",
        "print('ROUGE-2 Validation')\n",
        "print(vscores['rouge-2']['f'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5no57tfbifRP"
      },
      "source": [
        "!pip install tqdm boto3 requests regex sentencepiece sacremoses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjCE0Ti7jsGh"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eMl961Vicjk"
      },
      "source": [
        "#gpt2\n",
        "import nltk\n",
        "import rouge\n",
        "nltk.download('punkt')\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "torch.backends.cudnn.deterministic = True\n",
        "np.random.seed(100)\n",
        "torch.manual_seed(100)\n",
        "torch.cuda.manual_seed(100)\n",
        "import os\n",
        "apply_avg = True\n",
        "apply_best = False\n",
        "evaluator = rouge.Rouge(metrics=['rouge-n'],\n",
        "                           max_n=4,\n",
        "                           limit_length=True,\n",
        "                           length_limit=100,\n",
        "                           length_limit_type='words',\n",
        "                           apply_avg=apply_avg,\n",
        "                           apply_best=apply_best,\n",
        "                           alpha=0.5, # Default F1_score\n",
        "                           weight_factor=1.2,\n",
        "                           stemming=True)\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
        "CUDA_LAUNCH_BLOCKING=1\n",
        "ind = np.array(author_labels)\n",
        "#choose labels we want to use - two at a time\n",
        "a0 = np.where(ind==0)[0]\n",
        "a1 = np.where(ind==1)[0]\n",
        "ind[a0] = 0\n",
        "ind[a1] = 1\n",
        "avail_poems = np.array(r_authors_poem_line,dtype='object')[np.concatenate((a0,a1))]\n",
        "avail_ind = ind[np.concatenate((a0,a1))]\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2').to(device)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "bleu_ref = []\n",
        "bleu_hyp = []\n",
        "rouge_ref = []\n",
        "rouge_hyp = []\n",
        "ce = torch.nn.CrossEntropyLoss()\n",
        "lp = 0\n",
        "i = 0\n",
        "ct = 0\n",
        "while i < len(avail_poems):\n",
        "  for line in avail_poems[i]:\n",
        "    if len(line) > 0:\n",
        "      ct += 1\n",
        "      bleu_ref.append(line)\n",
        "      st=\"\"\n",
        "      j = 0\n",
        "      while j < len(line):\n",
        "        if j == len(line) - 1:\n",
        "          st += line[j]\n",
        "        else:\n",
        "          st += line[j] + ' '\n",
        "        j += 1\n",
        "      rouge_ref.append(st)\n",
        "      with torch.no_grad():\n",
        "        inputs = tokenizer(line,is_split_into_words=True,return_tensors='pt',max_length=15,truncation=True).to(device)\n",
        "        truth = inputs['input_ids']\n",
        "        outputs = model(**inputs,labels=inputs['input_ids'])\n",
        "        logits = outputs.logits\n",
        "      logits = logits.view((logits.size()[0],logits.size()[2],logits.size()[1]))\n",
        "      maxlog = torch.max(logits,1)[1].cpu().reshape(-1).tolist()\n",
        "      gst = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(maxlog))\n",
        "      rouge_hyp.append(gst)\n",
        "      bleu_hyp.append(gst.split())\n",
        "      lp += ce(logits,truth)\n",
        "  print(i)\n",
        "  i += 1\n",
        "print(lp/ct)\n",
        "tscores = evaluator.get_scores(rouge_ref, rouge_hyp)\n",
        "print('BLEU Score')\n",
        "print(nltk.translate.bleu_score.corpus_bleu(bleu_ref,bleu_hyp))\n",
        "print('ROUGE-1')\n",
        "print(tscores['rouge-1']['f'])\n",
        "print('ROUGE-2')\n",
        "print(tscores['rouge-2']['f'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g46sdbOosJc2"
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}